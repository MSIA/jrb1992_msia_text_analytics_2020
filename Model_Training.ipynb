{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from statistics import mean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import fasttext\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout, MaxPooling1D, Conv1D\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import gensim\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras import backend\n",
    "import json, multiprocessing\n",
    "from gensim.test.utils import get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data cleaning by handling duplicates and missing values.\n",
    "def data_cleaning(data):\n",
    "    \n",
    "    print(\"There are \" + str(len(data)) + \" reviews in this dataset.\\n\")\n",
    "    print(\"Let's print out the first few lines to see what the data looks like.\\n\")\n",
    "    print(data.head())\n",
    "    print(\"\\nChecking data types for variables... \\n\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    # Remove duplicate values\n",
    "    print(\"\\nChecking for duplicates values in 'description' (reviews)...\\n\")\n",
    "    print(data.description.describe())\n",
    "    # Since the duplicated() method returns False for duplicates, the NOT of the series yields unique values in dataset.\n",
    "    # Making a bool series \n",
    "    bool_series = data[\"description\"].duplicated(keep = False) \n",
    "    # Passing NOT of bool series to see unique values only  \n",
    "    data = data[~bool_series] \n",
    "    print(\"Duplicates removed. \\n\")\n",
    "    \n",
    "    # Handle missing values and data imputation\n",
    "    print(\"Checking for missing values in reviews...\\n\")\n",
    "    print(data.isnull().sum().sort_values(ascending = False))\n",
    "    # Remove specific regions \"region_1\", \"region_2\", \"designation\" regarding wine growing area since province also provides geographical information while having much less missing values.\n",
    "    # Remove vairables \"taster_name\", \"taster_twitter_handle\" by assuming the objectivity of scoring and reviews. In addition, we will not further collect data through Twitter API.\n",
    "    data = data.drop([\"region_1\", \"region_2\", \"designation\", \"taster_name\", \"taster_twitter_handle\"], axis =1)\n",
    "    print(\"\\nColumns 'region_1', 'region_2', 'designation', 'taster_name', 'taster_twitter_handle' are dropped.\\n\")\n",
    "    # Rows that have null values in columns 'province', 'country', and 'variety' are dropped.\n",
    "    data = data.dropna(subset=['province', 'country', 'variety'])\n",
    "    print(\"Rows that have null values in columns 'province', 'country', and 'variety' are dropped.\\n\")\n",
    "    # Replace null prices with the mean\n",
    "    print(\"Replace null prices with the mean value.\\n\")\n",
    "    data[\"price\"] = data[\"price\"].fillna(data[\"price\"].mean())\n",
    "    print(data.isnull().sum(), \"\\n\\n Data imputation completed. \\n\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top N wine varieties and keep only records with those varieties in current dataset.\n",
    "def top_variety_extraction(data, n):\n",
    "    \n",
    "    # Prepare the reviews dataset\n",
    "    data = data[[\"description\", \"variety\"]]\n",
    "    # Count the total number of wine variety\n",
    "    print(\"Number of wine variety: \", data['variety'].nunique(), \"\\n\")\n",
    "    count_variety = data.variety.value_counts()\n",
    "    # Take top N varieties with the most occurances\n",
    "    topN_distribution = count_variety.head(n) \n",
    "    # Only keep records with variety in this list\n",
    "    topN_bool = data[\"variety\"].isin(topN_distribution.index.to_list())\n",
    "    data = data[topN_bool].reset_index(drop = True)\n",
    "    print(\"We choose to keep top\", n, \"varieties with the most occurances since there are hundreds of labels.\")\n",
    "    \n",
    "    return data, topN_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The summary statistics for dataset which includes the number of reviews, the number of labels, label distribution, average / mean word length of documents.\n",
    "def summary_statistics(data, labels):\n",
    "    \n",
    "    # Number of reviews\n",
    "    num_doc = len(data)\n",
    "    # Number of labels\n",
    "    num_labels = len(set(labels.index.to_list()))\n",
    "    # Average / mean word length of documents\n",
    "    text_ls = []\n",
    "    label_ls = []\n",
    "    doc_len_ls = []\n",
    "    for i in range(len(data)):\n",
    "        text = data.iloc[i].description\n",
    "        label = data.iloc[i].variety\n",
    "        text_ls.append(text)\n",
    "        label_ls.append(label)\n",
    "        doc_len_ls.append(len(word_tokenize(text)))\n",
    "    avg_len = mean(doc_len_ls)\n",
    "    print(\"Number of reviews: \", num_doc)\n",
    "    print(\"Number of labels: \", num_labels)\n",
    "    print(\"Label distribution: \\n\", labels)\n",
    "    print(\"Average word length of reviews: \", avg_len)\n",
    "    \n",
    "    return text_ls, label_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for tokenization\n",
    "def tokenization(text, stopwords):\n",
    "    \n",
    "    # Apply nltk word tokenization, convert to lower cases, remove non-alphabetic chars and stopwords.\n",
    "    review_tokenized = [i.lower() for i in word_tokenize(text) if i.isalpha() and i not in stopwords]\n",
    "    \n",
    "    return review_tokenized\n",
    "\n",
    "# Apply nltk word tokenization, convert to lower cases, remove non-alphabetic chars and stopwords.\n",
    "def review_processing(labels, texts):\n",
    "    \n",
    "    # Remove list of stopwords that do not add much meaning to a sentence.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    texts_tokenized = [tokenization(i, stop_words) for i in texts]\n",
    "    cleaned_df = pd.DataFrame({'text': texts_tokenized, 'label': labels})\n",
    "    # Double check to remove null values.\n",
    "    cleaned_df = cleaned_df.dropna()\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets.\n",
    "def split_data(data): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size = 0.3, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TfidfVectorizer to transform text into feature vectors that can be used as input to estimator. \n",
    "def tfidf_transform(train, test, min_df, max_df, ngram):\n",
    "    # Sublinear tf scaling replaces tf with 1 + log(tf), addressing the problem that 20 occurrences of a word is probably not 20 times more important than 1 occurrence.\n",
    "    tfidf_vectorizer = TfidfVectorizer(sublinear_tf = True, min_df = min_df, max_df = max_df, ngram_range = ngram)\n",
    "    features_train = tfidf_vectorizer.fit_transform(train)\n",
    "    features_test = tfidf_vectorizer.transform(test)\n",
    "    return features_train, features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance evaluation metrics.\n",
    "def score_metrics(test, pred):\n",
    "    print(\"Precision:\", precision_score(test, pred, average='macro'))\n",
    "    print(\"Recall: \", recall_score(test, pred, average='macro'))\n",
    "    print(\"F1 score: \", f1_score(test, pred, average='macro'))\n",
    "    print(\"Accuracy: \", accuracy_score(test, pred))\n",
    "    print(\"Micro-averaged F1-score: \", f1_score(test, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 129971 reviews in this dataset.\n",
      "\n",
      "Let's print out the first few lines to see what the data looks like.\n",
      "\n",
      "    country                                        description  \\\n",
      "0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
      "1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
      "2        US  Tart and snappy, the flavors of lime flesh and...   \n",
      "3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
      "4        US  Much like the regular bottling from 2012, this...   \n",
      "\n",
      "                          designation  points  price           province  \\\n",
      "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
      "1                            Avidagos      87   15.0              Douro   \n",
      "2                                 NaN      87   14.0             Oregon   \n",
      "3                Reserve Late Harvest      87   13.0           Michigan   \n",
      "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
      "\n",
      "              region_1           region_2         taster_name  \\\n",
      "0                 Etna                NaN       Kerin O’Keefe   \n",
      "1                  NaN                NaN          Roger Voss   \n",
      "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
      "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
      "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
      "\n",
      "  taster_twitter_handle                                              title  \\\n",
      "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
      "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
      "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
      "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
      "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
      "\n",
      "          variety               winery  \n",
      "0     White Blend              Nicosia  \n",
      "1  Portuguese Red  Quinta dos Avidagos  \n",
      "2      Pinot Gris            Rainstorm  \n",
      "3        Riesling           St. Julian  \n",
      "4      Pinot Noir         Sweet Cheeks  \n",
      "\n",
      "Checking data types for variables... \n",
      "\n",
      "country                   object\n",
      "description               object\n",
      "designation               object\n",
      "points                     int64\n",
      "price                    float64\n",
      "province                  object\n",
      "region_1                  object\n",
      "region_2                  object\n",
      "taster_name               object\n",
      "taster_twitter_handle     object\n",
      "title                     object\n",
      "variety                   object\n",
      "winery                    object\n",
      "dtype: object\n",
      "\n",
      "Checking for duplicates values in 'description' (reviews)...\n",
      "\n",
      "count                                                129971\n",
      "unique                                               119955\n",
      "top       Seductively tart in lemon pith, cranberry and ...\n",
      "freq                                                      3\n",
      "Name: description, dtype: object\n",
      "Duplicates removed. \n",
      "\n",
      "Checking for missing values in reviews...\n",
      "\n",
      "region_2                 66932\n",
      "designation              31601\n",
      "taster_twitter_handle    27669\n",
      "taster_name              23580\n",
      "region_1                 17869\n",
      "price                     7784\n",
      "province                    55\n",
      "country                     55\n",
      "variety                      1\n",
      "winery                       0\n",
      "title                        0\n",
      "points                       0\n",
      "description                  0\n",
      "dtype: int64\n",
      "\n",
      "Columns 'region_1', 'region_2', 'designation', 'taster_name', 'taster_twitter_handle' are dropped.\n",
      "\n",
      "Rows that have null values in columns 'province', 'country', and 'variety' are dropped.\n",
      "\n",
      "Replace null prices with the mean value.\n",
      "\n",
      "country        0\n",
      "description    0\n",
      "points         0\n",
      "price          0\n",
      "province       0\n",
      "title          0\n",
      "variety        0\n",
      "winery         0\n",
      "dtype: int64 \n",
      "\n",
      " Data imputation completed. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "# import data\n",
    "data = pd.read_csv(\"winemag-data-130k-v2.csv\", index_col = 0)\n",
    "cleaned_data = data_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'designation', 'points', 'price', 'province',\n",
       "       'region_1', 'region_2', 'taster_name', 'taster_twitter_handle', 'title',\n",
       "       'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wine variety:  686 \n",
      "\n",
      "We choose to keep top 10 varieties with the most occurances since there are hundreds of labels.\n"
     ]
    }
   ],
   "source": [
    "# Keep top 10 varieties with the most occurances.\n",
    "topN_data, labels = top_variety_extraction(cleaned_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAJXCAYAAAAq8RozAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeVyU5f7/8TebuEAuBEpmHTW3tLTESi3IrEBRU1xO7p4Wy9yy8pcnPZqWRy1T09TsHLXkqGmmYAaY+14ux6NWVKbino4KssMA8/vDLyPIIiA4V/p6Ph4+HO/7uu/53NcM+J57rvu6nWw2m00AAAAAjOPs6AIAAAAA5I+wDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOlEDfvn3VoEEDNWjQQHPnzi3ydhMmTLBvd+rUqTKssOxkH/sDDzzg6FKMYrVaNXfuXLVv317NmjVT8+bNFRQUpP379xdp++z3xVNPPVXGlRbMhNd25cqV9r749ttvb+pz5/y5LuhPkyZN9OijjyokJESTJk3Sr7/+elNrLK4pU6bYa581a1axt//ll1/s27/88stlUGHh0tLS7M//2muvldnzpKen6+jRo2W2f+BGENaBGzRnzhwdOXLE0WXAwUaOHKkZM2boyJEjSklJUWJioo4dOyYfHx9Hl4ZSZLVaFRcXp59++kmff/65OnfurOnTpzu6rAKFhITYH69Zs6bY24eHh+e7r1vJ1q1b1aFDB61fv97RpQD5cnV0AcCfXXp6ukaPHq0lS5bI2ZnPv7ejI0eOKDIyUpJUs2ZNvfnmm7r77rt1+fJl1axZ08HVoSQ+++yzfD9oZWRkKCEhQT/88IO++OILpaSk6NNPP1XVqlU1YMCAm1/oddSrV08PPPCADh06pJiYGP34449q0qRJkbbNysqyB/wqVaqobdu2ZVmqQ8TExDjkGwOgOAjrQCnYv3+/Fi1aZOR/1ih7v//+u/3xq6++quDgYAdWg9JQt25d3X333QWub9WqlVq1aqUXXnhBGRkZ+vjjj9WtWzd5eHjcxCqLpkuXLjp06JCkK2fXixrWd+3apfPnz0uSOnbsqHLlypVZjQVxd3cv06FGmZmZZbZvoLRwGhC4Ac7OznJ1vfKZd8aMGTp58qSDK4IjpKSk2B8XFvBwa3n00UcVFBQkSUpOTtaGDRscXFH+OnToYA/aERERysrKKtJ2OYfAdOvWrUxqA3B9hHXgBri6uurFF1+UdCWwjRkzxsEVwRFyhh8XFxcHVoKbzd/f3/74t99+c2AlBatcubKefvppSdK5c+e0Z8+e626TnJysdevWSZIaN26shg0blmmNAArGMBjgBg0ZMkTr1q3T0aNH9f3332v58uXq0aNHsfcza9YsffLJJ5KkZcuWqVmzZvm2mzBhghYvXixJ2rBhQ64zuX379tXu3bsVGBiomTNnat++ffriiy/03//+V/Hx8fL29labNm00cOBA+3jcEydOaP78+dq2bZvOnz8vT09PNW/eXK+88kqRZgXZs2eP5s+fr/379ys1NVU1atRQQECABgwYoLvuuqvQbVNSUrR06VKtX79eR48eVWJioqpUqaImTZqoY8eOateuXb7XAfzwww/q16+fJCksLEznz5/X9OnTdeTIEVWqVEkNGjTQBx98oOrVq1+3/mzp6ekKCwvT2rVrFR0drfj4eHl6euq+++7T008/rb/+9a8qX758rm2y+zun7LokadGiRXr00UeLXENpSEtLU3h4uLZs2aLo6GjFxsbKarWqcuXKqlevnp588kn16NFDFStWvO6+HPHaXk9GRoZWr16tiIgI/fzzz7p8+bIqVaqku+66S4899ph69uype++9t9j7LSkvLy/744SEhHzbxMXF6T//+Y82b96sEydOKCUlRV5eXmratKlCQkIUEBCQ73YrV67U3//+d0lXXosNGzZo3rx5OnXqlL0vP/74Y7m7u1+3zpCQEEVEREi6MhTmeu/LdevWKTk52b5tQY4fP66vvvpKu3fv1qlTpxQfH69y5crJy8tLDz30kEJCQvTYY4/l2e7IkSNq3769JOlf//qXKlWqpClTpig6OloVK1ZU3bp19d577+nuu+/Wgw8+KElq27at5syZk28dp0+fVmhoqHbs2KHTp08rMzNT3t7eatGihXr27GnfR7a0tLQ8yz766CN99NFHkq78Dt65c6c+/vhj+7oOHToU2A+7d+9W3759JUnvv/++unfvXmBboLgI68ANKleunCZOnKjevXsrKytLH3zwgQICAooVFMvCp59+qhkzZshms9mXnTp1SqGhoVq/fr2WLVumn3/+WW+++aaSkpLsbS5duqR169Zp8+bNmjt3rp544okCn+Pzzz/X5MmTcz1HTEyMYmJitGzZMk2ePFnt2rXLd9uDBw9qyJAhOnfuXK7lFotFmzZt0qZNmxQaGqqZM2cWOqPKli1b9PHHH9vPbqenp+v06dPFmoXll19+0euvv65jx47lWn7p0iXt3r1bu3fv1sKFCzVr1iyjp6z86aef9Nprr+mPP/7Is+7ChQu6cOGCdu3apaVLl2rRokWFvkdNeG2vlZCQoIEDB+q///1vruWXL1/W5cuXFR0drUWLFmn06NHq3bt3kfd7Iy5evGh/XLVq1Tzrt2zZorfeekvx8fG5lp89e1Znz55VVFSUnnrqKX344YeFjnf/8ssv7UFSutKXSUlJRQrqktS6dWtVr15d586d03fffaexY8fKzc2twParV6+WdOX3W8eOHfNtM2vWLM2dOzfPuG+r1aqkpCSdOHFC4eHhGjBggP1DR34OHjyoefPmKT09XdKVn+Hff/+9yEPKlixZokmTJtm3z3by5EmdPHlSK1euVN++fTVq1Cj7sMWi6NKli2bNmqWsrCx98803hYb17P4qX758gT8XQEkR1oFS8PDDD6t3794KDQ1VQkKCxo0bp08//dRh9ezevVtr165V9erV9eKLL6pJkyayWCz69NNPFR0drbNnz+qtt97SwYMH5e7urhEjRqhFixZKT0/XihUrtGbNGlmtVo0fP17fffddvmdA09PTNWnSJJUvX14DBgzQE088oYyMDK1fv15Lly5Vamqq3nzzTd11111q2rRprm0PHz6s/v37Kzk5WRUqVFDPnj3VunVr3XHHHTp79qy+/fZbrV27Vvv379cLL7ygZcuWqVKlSvke68cffyxPT08NHz5cjRo10m+//aZy5crJycmpSH0VExOjv/3tb7p06ZIkqU2bNurcubPuuusunT9/XmvWrFFkZKTOnj2rfv36admyZapfv76kK2fQsscqZ89h/f7779sv4LvnnnuK9oKVgtjYWL3wwguKi4uTi4uLQkJC9OSTT+rOO++0B9nPP/9csbGxiomJ0ZQpUzRt2rR892XKa3utSZMm2YN6t27d9Mwzz8jLy0uXL1/W7t27FRoaquTkZL3//vt6+OGH1ahRoxvr1CLYsmWL/fG134bt2rVLgwYNUmZmpqpUqaLevXurRYsWqlixok6cOKGVK1dq586d2rhxo4YMGaL58+cXOIxq+vTp8vX11euvv65atWrpwIEDql27dpHrdHZ2VufOnTVv3jzFxcVp27ZtBc7pb7FYtGvXLknS008/rcqVK+dps2TJEvs3gXfddZd9jvqKFSvq7NmzWr9+vSIiImSz2fT555+rbdu2euSRR/J9vtmzZ8vd3V0jR47Uww8/rJiYGCUmJsrd3V1paWmFHtfSpUs1fvx4SVdmYurTp48efPBBubi46Pfff9fixYsVHR2t0NBQpaena8KECZKufAgJCwvT6dOnNXjwYElXvinr2rWrJOkvf/mLKlSooMcee0w7d+7U9u3bdenSJVWrVi1PDWlpaYqKirL3l4kXGeNPzgag2Pr06WOrX7++rUmTJvZlSUlJtjZt2tjq169vq1+/vm316tV5ths/frx9/cmTJ3Otmzlzpn3d/v37C3zuwvaRXVf9+vVtjz/+uO2PP/7Itf7SpUu2Bx980N7Gz8/PdvTo0TzPMXToUHub6OjoAp+jWbNmtgMHDuTZfsOGDbYGDRrY6tevbwsJCcmz/rnnnrPVr1/f1rJlS9vvv/+e73EuW7bM/jwffvhhrnXff/+9fV39+vVt27dvz7+zimDAgAH2/SxYsCDfNitXrrS36dixoy0rKyvX+q+//tq+/vvvvy9RHdnbt2nTpkTbT5s2zb6PhQsX5tvmjz/+sDVv3txWv3592wMPPGCzWq251pvw2ubsyzVr1tiXp6Wl2Zo0aWKrX7++bfTo0fnud/PmzfZtJ0yYkG+bwuQ8/mt/tvKzbt06W8OGDW3169e3BQQE2NLT0+3rUlJSbK1bt7bVr1/f9uyzz+b5WcyW83VbsmRJrnU5+6JRo0YF9mdRHT161L6/N954o8B2CxYssLfbtm1bnvUZGRm2li1b2urXr2979NFHbWfOnMl3P//+97/t+xk/fnyudb///nuun+FVq1blu4/U1FR7m0GDBuVad+rUKft7ok+fPrbExMQ821utVtvw4cML/PnMWce8efPybB8eHm5f/5///CffGiMiIgrtL+BGcYEpUEoqVqyo9957z/7viRMn2s/WOsLAgQPzDHOoWrVqrrNb/fr1y/fsXM4zbsePHy/wOYYMGZJn3Gf29l26dJEk/fjjj/Zp4yRpx44dio6OliS98cYbqlu3br777tGjh1q1aiXpytkzq9Wab7t77rlHrVu3LrDGwkRHR2vnzp2SpCeffFJ/+9vf8m3XpUsX+7jdX3/9VVu3bi3R85Wl8+fPy9vbW97e3gUOAalevbr99U9LS1NcXFyB+zPhtc0pPj7ePsyhoDHpAQEB6tu3r4YMGZLrws+SOHLkiKKjo/P82bdvn8LCwvT6669r6NCh9uFXY8aMyTWsZPXq1bJYLJKkd999t8AhR8OGDbP/DC5atKjAeh555JEC+7OoateurYceekiStHHjRvuY9GtlzwLj6+trf51yOnHihLy8vFSpUiX16NFDvr6++e6nU6dO9sfXDonKydPTs8ChNoXJPlvu7OysDz74IN9vaFxdXTV+/Hj7usL6OD/PPvusPD09JUnffPNNvm2y+6t69er59hdwowjrQClq3bq1PdTFxsbmCu83W0H/aeQMDS1btsy3Tc6L5gr6D93Z2bnQi6g6d+5sf7xjxw77482bN9sfXy9kZ194l5iYmCsU5nTtMIzi2LZtm/3xX//610Lb9uzZM9/tTDFp0iRt375dW7duLXQs8p133ml/fO0Y32ymvLY5eXl5qUqVKpKkefPmadWqVUpNTc3TbsyYMRo6dGiBF20W1cCBA9W5c+c8f3r16qW3335bkZGRysrKkru7u/75z3/aZ1vJlt0Xbm5uhV7M6eLioscff1ySdPTo0QJD7Y28z3PKHuZR0FSTv/32m/0DV5cuXfIdAle7dm198803+u9//6vXX3+9wOfy8vKyb1/Qe02SmjRpUqJZlLL7uE6dOgV+YJCuzIaT/SHlhx9+KPLUlVLuMej79+/XiRMncq2/dOmStm/fLkl67rnnuDEeygRj1oFS9ve//13btm2TxWJRRESEgoOD8/xHfjMUdOfMnDc28fb2vm4bW44LDHP6y1/+ojvuuKPA57///vvtj3NOaZcdBKQrZ7OL6uTJk3r44YfzLC/sP+nrOXz4sP1xQbPvZLv//vvl5uYmq9Vq7BR9kuxhwWq16syZMzp58qRiYmL022+/af/+/blqLyi0mPLa5uTk5KSXXnpJU6dOVUJCgkaNGqVx48bJz89PLVu21OOPP66GDRsW+VqFkqpYsaIqV66s++67Ty1atFDXrl1zfQDKlt0XVqu1WGPnT548me9Z+Bt5n+fUrl07TZw4USkpKfr222/znNHOPkvs5ORU6Cww2bLfbwkJCTp58qSOHz9u/1Zi37599vdYYQG5JMeWkpJivyD8999/V4MGDYq0XUJCguLi4vIde16QkJAQLV++XNKVs+vZY9ylK/PWZ38zlPNDLFCaCOtAKbvjjjv07rvv2n+hv/vuu3rkkUcKDT+lzcXFJc80gwW1K6mcZ9/z4+npaQ+3ly9fti+PjY0t0fNdO5tGthu5mCt7GIizs3O+M3nk5OrqqipVqshisRQ6fMSRUlJStGTJEq1Zs0a//fabMjIy8rRxdna+7plFU17ba7388svKysrSnDlzlJqaqrS0NO3YsUM7duzQ1KlT5ePjo8DAQA0YMOCGb0517bSoxWXS+/za/Tz77LMKDw/X9u3bFRcXZ//GIisrS2vWrJEktWjRQrVq1Sp0X7/99psWLlyo7du32+90mlNRPzgV9QLjnG7kZzA+Pr5YYf2hhx5S7dq1dezYsTxhPfvDzYMPPnjDw5SAghDWgTLw9NNPKygoSFFRUbJYLJo8ebL++c9/lsq+i/IVrik35sk+K59zWEZ2gKxataoWLlxY5H0VNOb3Rs6kFufr8JztTfyq++TJk3rxxRdzXWPg5uam2rVrq06dOmrcuLEeeeQRhYeHa8mSJTf8fDfjtc3PK6+8oueff17r1q3Txo0b9f3339unHj1//rxCQ0O1fPlyzZgxo8DZTm6G7L5o0KCBpkyZUuTtCvqAUJrfGHTp0kXh4eGyWq1au3atfQjYDz/8YJ/2M3u4TEGWLl2q9957L9e0jVWqVFHdunVVr149NWvWTK1atVKbNm3yTO14rZIcW84Pok899ZSGDRtW5G2vd4+A/ISEhOijjz7SsWPHdOjQIT3wwAM6duyYDh48KImz6ihbhHWgjIwdO1bff/+94uLi9PXXXys4OLjQ9jn/wypo6IlU8I1XbracZ1TzExcXlyu8Zcs+ixcfH686deoUeZ7ospDzjGJsbGyhZ9usVqv9rGd+U9k52ptvvmkP6h06dFCfPn3UpEmTPOPXv/zyy+vuy/TXtnLlyurWrZu6deumjIwMHTp0SDt27FBUVJQOHz6stLQ0vf3229q0aZPDptHL/hYmNjb2pkwhWRyPPfaYatasqdOnT2vNmjX2sJ49V7iHh4cCAwML3P7QoUP2oO7p6amhQ4fq6aefzjP0Lj09/bpBvaSy32vSlfH3Zd3Hzz33nGbMmKHMzExFRkbqgQcesN9kqly5ctf9/Q7cCPNODwG3CC8vr1w3AvnHP/6hlJSUAtvnPBue34Vz2c6ePVs6Bd6g48ePF3rRWPYZJyn3GOd69epJkjIzM6972/OdO3dqwYIFWrt2bZnMrJNznOuBAwcKbfvTTz/Zx6bWqVOn1Gu5EYcOHbLX/+ijj+qjjz7SQw89lO+FpmfOnLnu/kx9bf/44w/t2rUr11lVV1dXPfTQQxoyZIi++eYbe8iMj4/Xvn37irTfspDdF+fPn89zs61rRUVF6YsvvtD69esLvKC7NDk5Odln9Nm7d68uXLig9PR0rVu3TpIUHBysChUqFLj9l19+aQ/hEyZMUP/+/fO9Rub06dNlUP0Vnp6e9rHuBw4cKPR3pnTlm4DFixdry5Ytxf5GTco900v2hbnZf7dp0ybXhwegtBHWgTLUuXNn+xRyp0+fLnDqL0m5xrSfOnUq3zaXLl3KFZQcKS0tLd/ZJLKtWLFC0pVgkD3bhaRcj7/44osCt7fZbHrvvfc0ZcoUDRs2rNAPOiWVs5Zly5YV2nbp0qX2xyWdKrKs5JyhonHjxgW2O3XqVK67fxZ01tPE13bOnDkKCAjQgAEDCvwg4OTklOuOu4V94ChrRe2L5ORkjRs3Tv/85z81cuTIMr9ANluXLl3k5OSkrKwsbdy4Ubt27bJ/a3e9C0tzvt+ybwCWn+wz9VLB77Ubkf1zmJKSYr8AND/Hjx/XhAkTNGHCBE2ZMiXXMLbiDGnL7peYmBjt3LlTP/30kyTZP/gAZYWwDpSxCRMm2C+gKmw+6ZxneZctW5anbUZGht59990izUl9s0ycODHfM7WrVq3S2rVrJV2ZFSTnXO7PPPOM/cK1rVu36l//+le++/7oo4909OhRSVLbtm0LnN3mRtx///32ecc3bdpU4BzMYWFhCgsLk3TlrHpxZjq5GXIORdm1a1e+7xGLxaLhw4fnWldYmDXttW3Tpo398bRp0/K9s2VWVpZ9aIKzs3Ous/43W/fu3e1DcL788kt7XTnZbDb94x//sF8s2a1bt0LPaJemu+++Wy1atJAkrV+/Xt99950kqW7dutedGSnn+62gew6sX78+1+tfFh+c+vfvbw/b06dP1/79+/O0SU1N1dtvv20/m963b99c63POfJV97UNBct7NNfuuqV5eXrk+IAJlgTHrQBnz9fXVW2+9Zf/lXpCHHnpI99xzj06cOKFDhw5pwIAB6t+/v7y9vXX06FEtXrxYP/30k72No1WoUEEWi0Vdu3bVyy+/rGbNmik5OVnffvutVq1aJenKuNJ3330313YuLi6aMmWK+vfvL6vVqqlTp2rPnj0KCQmRr6+vzp49q5UrV9pv4165cmW98847ZXYcEydOVNeuXRUfH6+JEydq165d6ty5s3x9fWWxWPTtt9/ag5a7u7umT58uV9ey+9V5+fLlIl+Q2LZtW/n5+al58+by9vaWxWJRdHS0BgwYoN69e6tmzZqKi4vTnj17tGLFijwzlBR0/YOJr22jRo0UGBiotWvX6uDBg+rUqZP69eunOnXqyM3NTadOndKXX35pD2xdunQpkw94RXXHHXfovffe04gRI2Sz2fTGG29ow4YNCg4OVrVq1XTixAktWbLEXu/dd9+toUOH3tQau3btqt27d2vXrl2qWLGifdn1BAUF2T+wTZkyRWfOnFGrVq1UqVIlnTx5UpGRkdq4cWOubcriWpv69etr8ODBmjVrlpKTk9W3b189//zzatOmjSpUqKDDhw9r4cKF9mFIzZs3V48ePXLt484777TPkLR69Wo98sgjqlSpkurUqZNnBq9y5cqpffv2Wrp0qWJiYiRJHTt2LNPfB4BEWAduip49eyoyMlK7d+8usI2Li4s+/PBDvfTSS0pISNDevXu1d+/eXG3atm2rzp073/T/1PPTqFEjtWjRQvPmzcs3XPr6+mrevHmqUaNGnnXNmzfXZ599phEjRiguLk5btmyxB7icatSoodmzZ9/wNHyFueeeexQaGqrBgwfr1KlT2rhxY56gIUm1atXS9OnT1bBhwzKrRbpyk6AFCxYUqW316tXl5+cnd3d3ffjhh3r11VeVmpqa73tHujJ/erdu3TR16lRJV+anzm9+c1Nf24kTJ+rixYvau3evYmJiNGHChHzbPfPMM3k+SDhC+/btlZGRobFjxyolJUVr1qyxT42YU7169TR37tybOr2rJAUGBmrChAlKSkpSenq6XF1d9dxzz113u/bt22vr1q1atWqV0tPTNX/+fM2fPz9Pux49euiPP/7Q1q1bdeLECaWnp+c6k10ahgwZIhcXF82aNUtWq1WhoaEKDQ3N0+6xxx7TrFmz8syU5e7uLn9/f23evFlnzpzRCy+8IOnKtz8dOnTIs5+QkJBcQ+IYAoObgbAO3AROTk56//331alTp0IvhGrWrJkiIyO1YMECbdq0SWfOnFGFChXUoEEDdevWTZ06ddKmTZtuYuWFe+ONN/Tggw/qiy++UHR0tDIzM3XPPfcoMDBQ/fv3L3T+5FatWmnDhg1aunSpNm/erCNHjighIUEVK1bUfffdp7Zt2+r555+/KbN5NGzYUJGRkfrqq6+0bt06/frrr0pISJCXl5dq166tDh06XPeiO0dr2bKlVq1apQULFmjXrl32O2FWrVpV9erVU1BQkDp16qSMjAzNnj1bKSkpioyMzHOmMZuJr62np6dCQ0O1Zs0aRUREKDo6WhcvXpSLi4vuvPNOPfzww3ruuedyjRd3tE6dOqlVq1ZavHixtm3bphMnTigpKUkeHh5q2LCh2rVrp5CQkFIPsUVRoUIFtWvXzn4NQkBAQL43eMrP5MmT1bp1a3399deKjo5WQkKC3N3d5evrq6ZNm+qvf/2rmjVrpsWLF2vr1q1KTU3Vpk2bCp1lpqQGDRqkdu3aafHixfr+++915swZpaWlqUqVKmrSpIk6deqkdu3aFXg9wIcffqipU6dq06ZNio2N1R133FHgRc8PPvig7r77bp06dUqNGjUq8w/vgCQ52QqbIw4AAACSrlzk/8QTTygjI0N///vfNWDAAEeXhNsAF5gCAAAUQXh4uDIyMuTm5qZOnTo5uhzcJgjrAAAA13Hy5En72PygoKBCb6IGlCbGrAMAAORj8eLF2r9/v5ycnLR161bFxcXJzc1Nr7zyiqNLw22EsA4AAJAPq9Wa52Z2w4YNs9+hFrgZCOsAAAD5aNy4sXx9fXXx4kXde++9GjBggLp16+bosnCbYTaYQsTGJikri+4BAABA2XB2dlLVqgVPh8uZ9UJkZdkI6wAAAHAYZoMBAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAM5eroAv6MPCq5qkLFCo4uo9SlJKcoMSnD0WUAAADg/xDWS6BCxQqqW6Oeo8sodUf+OKzEpARHlwEAAID/wzAYAAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUA4P64mJierQoYNOnTu/KsUAACAASURBVDolSdq5c6c6duyoZ599VtOnT7e3i46OVkhIiAIDAzV69GhlZGRIks6cOaPevXsrKChIgwYNUlJSkiQpPj5eAwcOVLt27dS7d29ZLJabf3AAAADADXBoWD9w4IB69uypmJgYSVJqaqreeecdzZkzRxEREfrxxx+1ZcsWSdLIkSM1duxYrV27VjabTcuXL5ckjR8/Xr169VJUVJSaNGmiOXPmSJJmzJghPz8/RUZGqnv37po4caJDjhEAAAAoKYeG9eXLl2vcuHHy8fGRJB08eFD33nuvatWqJVdXV3Xs2FFRUVE6ffq0UlNT1axZM0lSSEiIoqKiZLVatWfPHgUGBuZaLkmbN29Wx44dJUkdOnTQ1q1bZbVaHXCUAAAAQMm4OvLJrz3bff78eXl7e9v/7ePjo3PnzuVZ7u3trXPnzik2NlYeHh5ydXXNtfzafbm6usrDw0OXLl1S9erVi1yfl5dHiY/tz8rb29PRJQAAAOD/ODSsXysrK0tOTk72f9tsNjk5ORW4PPvvnK79d85tnJ2L90XCxYuJysqy5Vl+KwdaiyWhWO09PMqpQgX3MqrGcVJS0pSYmO7oMgAAwC3O2dmp0BPERoX1GjVq5LoQ1GKxyMfHJ8/yCxcuyMfHR9WqVVNCQoIyMzPl4uJiby9dOSt/4cIF1ahRQxkZGUpKSlKVKlVu+jHd6ipUcNejTYIcXUap++HHKMI6AABwOIfPBpNT06ZNdezYMR0/flyZmZlas2aN/P39VbNmTbm7u2vfvn2SpPDwcPn7+8vNzU1+fn6KiIiQJIWFhcnf31+SFBAQoLCwMElSRESE/Pz85Obm5pgDAwAAAErAqDPr7u7umjx5soYOHaq0tDQFBAQoKOjKWdupU6dqzJgxSkxMVOPGjdWvXz9J0rhx4zRq1CjNnTtXvr6+mjZtmiRp+PDhGjVqlIKDg+Xp6ampU6c67LgAAACAknCy2Wx5B2VDUuFj1uvWqOeAisrWkT8OF3vMure35y07DKa4fQEAAFBc1xuzbtQwGAAAAABXEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEO5OroA4Fbh6emu8uXLObqMUpeamq6EhDRHlwEAwG2JsA6UkvLly+nZNsMcXUap+27TTMI6AAAOwjAYAAAAwFCEdQAAAMBQxob18PBwBQcHKzg4WFOmTJEkRUdHKyQkRIGBgRo9erQyMjIkSWfOnFHv3r0VFBSkQYMGKSkpSZIUHx+vgQMHql27durdu7csFovDjgcAAAAoLiPDekpKiiZOnKjQ0FCFh4dr79692rlzp0aOHKmxY8dq7dq1stlsWr58uSRp/Pjx6tWrl6KiotSkSRPNmTNHkjRjxgz5+fkpMjJS3bt318SJEx15WAAAAECxGBnWMzMzlZWVpZSUFGVkZCgjI0Ourq5KTU1Vs2bNJEkhISGKioqS1WrVnj17FBgYmGu5JG3evFkdO3aUJHXo0EFbt26V1Wp1zEEBAAAAxWTkbDAeHh4aPny42rVrpwoVKqhFixZyc3OTt7e3vY23t7fOnTun2NhYeXh4yNXVNddySTp//rx9G1dXV3l4eOjSpUuqXr36zT8oAAAAoJiMDOu//PKLvv76a23atEmenp566623tGPHDjk5Odnb2Gw2OTk52f/O6dp/59zG2bnoXyZ4eXmU7AD+xLy9PR1dgjHoi6voCwAAHMPIsL59+3a1bNlSXl5ekq4MbZk/f36uC0QvXLggHx8fVatWTQkJCcrMzJSLi4ssFot8fHwkST4+Prpw4YJq1KihjIwMJSUlqUqVKkWu4+LFRGVl2fIsv5WDi8WSUKz29MVV9AUAACguZ2enQk8QGzlmvWHDhtq5c6eSk5Nls9m0ceNGPfLII3J3d9e+ffskXZktxt/fX25ubvLz81NERIQkKSwsTP7+/pKkgIAAhYWFSZIiIiLk5+cnNzc3xxwUAAAAUExGnll//PHH9fPPPyskJERubm564IEHNHDgQD3zzDMaM2aMEhMT1bhxY/Xr10+SNG7cOI0aNUpz586Vr6+vpk2bJkkaPny4Ro0apeDgYHl6emrq1KmOPCwAAACgWJxsNlvecR6QVPgwmLo16jmgorJ15I/DJRr68WiToDKqyHF++DGqRH3xbJthZVSR43y3aSbDYAAAKCN/ymEwAAAAAAjrAAAAgLEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChXB1dAIBbj6dneZUv7+boMkpVaqpVCQmpji4DAHCbIawDKHXly7upXc+pji6jVEUufYuwDgC46RgGAwAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYqtTDenp6umJiYkp7twAAAMBtp1hhvVGjRpo9e3ahbT755BN17979hooCAAAAILkWtvLHH3/UuXPn7P+22Ww6evSoNmzYkG97q9WqzZs3KyMjo3SrBAAAAG5DhYb1y5cva/DgwXJycpIkOTk5KSIiQhEREQVuY7PZ1L59+9KtEgAAALgNFRrWW7durbFjx+rSpUuy2WyaPXu2WrRooUcffTTf9m5ubqpevTphHQAAACgFhYZ1SerVq5f98e7du9W1a1d17ty5TIsCAAAAUISwnlNoaGhZ1QEAAADgGsUK65KUnJysqKgoxcTEKD09XTabLU8bJycnjRo1qlQKBAAAAG5XxQrrv/zyi/r376/4+Ph8Q3o2wjoAAABw44oV1qdNm6bLly+rR48e8vf3l6enp32mGAAAAAClq1hhfe/evWrTpo0mTJhQVvUAAAAA+D/FuoOps7Oz6tSpU1a1AAAAAMihWGHdz89Pe/fuLataAAAAAORQrLA+cuRIxcTE6P3339e5c+fKqiYAAAAAKuaY9fHjx+uOO+7Q4sWLtXjxYrm7u6tcuXJ52jk5OemHH34otSIBAACA21GxwvqpU6ckSb6+vmVSDAAAAICrihXWN27cWFZ1AAAAALhGscasAwAAALh5inVmfcOGDUVu27Zt22IXAwAAAOCqYoX1wYMHF/mOpdHR0SUqKNvGjRv1ySefKCUlRa1bt9aYMWO0c+dOTZo0SWlpaWrXrp1GjBhhf67Ro0crKSlJfn5+Gj9+vFxdXXXmzBmNHDlSFy9eVO3atTV16lRVqlTphuoCAAAAbpZSCespKSk6ceKEtmzZoqZNm6p///43VNTJkyc1btw4ffXVV/Ly8lL//v21ZcsWjRs3TqGhofL19dUrr7yiLVu2KCAgQCNHjtT777+vZs2a6Z133tHy5cvVq1cvjR8/Xr169VJwcLBmz56tOXPmaOTIkTdUGwAAAHCzFCusDx06tND1P//8s3r16qWEhIQbKmrdunVq3769atSoIUmaPn26jh8/rnvvvVe1atWSJHXs2FFRUVG67777lJqaqmbNmkmSQkJCNHPmTHXv3l179uzR7Nmz7cv79OlDWAdwU3neUV7l3d0cXUapSk2zKiE+1dFlAMBtoVhh/Xruv/9+BQUFacGCBerSpUuJ93P8+HG5ubnp1Vdf1dmzZ/Xkk0+qXr168vb2trfx8fHRuXPndP78+VzLvb29de7cOcXGxsrDw0Ourq65lheHl5dHiY/hz8rb29PRJRiDvriKvriipP3w9LBPSrkSx1o/c4jKe99aH0AAwFSlGtYlqWrVqjp+/PgN7SMzM1N79+5VaGioKlasqEGDBql8+fK5huDYbDY5OTkpKysr3+XZf+dU1PH22S5eTFRWli3P8ls5uFgsxftWhL64ir646lbti+L2g0RfAAAK5+zsVOgJ4lIN65cuXdLatWtznekuiTvvvFMtW7ZUtWrVJElPP/20oqKi5OLiYm9jsVjk4+OjGjVqyGKx2JdfuHBBPj4+qlatmhISEpSZmSkXFxd7ewAAAODPolhhfciQIfkut9lsSk5O1sGDB5WcnKzBgwffUFFt2rTR22+/rfj4eFWqVEnbtm1TUFCQPvvsMx0/flx333231qxZo65du6pmzZpyd3fXvn371Lx5c4WHh8vf319ubm7y8/NTRESEOnbsqLCwMPn7+99QXQAAAMDNVKywvn79+kLXV65cWQMGDNCgQYNuqKimTZvqpZdeUq9evWS1WtW6dWv17NlTderU0dChQ5WWlqaAgAAFBQVJkqZOnaoxY8YoMTFRjRs3Vr9+/SRJ48aN06hRozR37lz5+vpq2rRpN1QXAAAAcDOVyk2RnJyc5ObmJi8vLzk7l85NUbt166Zu3brlWtayZUutXr06T9uGDRtqxYoVeZbXrFlToaGhpVIPAAAAcLMVK6zXrFmzrOoAAAAAcI0SXWC6d+9eff311/r111+VkpKiKlWqqF69eurUqZP8/PxKu0YAAADgtlTssP7RRx/p3//+t2y2K1MaVqhQQTExMdq/f7+++uorDRw4UCNGjCj1QgEAAIDbTbEGmEdEROhf//qX7rvvPs2bN0979+7V/v37deDAAS1YsEANGjTQZ599dt0LUQEAAABcX7HC+qJFi+Tt7a1FixYpICBAHh5XJnAvV66cWrVqpQULFujOO+/kok4AAACgFBQrrP/6669q06aNqlatmu/6atWqqU2bNoqOji6V4gAAAIDbWenMs3gNq9VaFrsFAAAAbivFCusNGjTQpk2bFBcXl+/6S5cuaePGjWrQoEGpFAcAAADczooV1vv16yeLxaIXX3xRu3fvVkZGhiQpMTFRW7Zs0YABA3Tx4kX16dOnTIoFAAAAbifFmrqxffv2OnTokBYuXKj+/fvL2dlZ5cqVU2pqqiTJZrPpb3/7mzp06FAmxQIAAAC3k2LPs/7222+rbdu2WrlypX755RclJSWpUqVKatiwoUJCQrgpEgAAAFBKSnQHUz8/P0I5AAAAUMaKPGb96NGjio2NzXfdzJkztW/fvlIrCgAAAEARwnp6erpGjBihDh06aMuWLXnWWywWzZkzR3369NHgwYOVmJhYJoUCAAAAt5tCw3pmZqZeeuklRUZGqkaNGvneDKlChQp66623dM8992jDhg169dVXZbPZyqxgAAAA4HZRaFj/8ssvtXv3bnXq1EnfffedAgIC8rTx8PDQSy+9pPDwcLVt21b79u3TihUryqxgAAAA4HZRaFj/5ptvdNddd2nixIlydS38WtTy5ctrypQpqlq1qsLCwkq1SAAAAOB2VGhYP3z4sB5//HG5ubkVaWceHh5q3bq1fv3111IpDgAAALidXXfMuqenZ7F2WL16dfudTQEAAACUXKFh3dfXVydOnCjWDk+cOKHq1avfUFEAAAAArhPWW7Rooa1bt8pisRRpZxaLRZs3b1aDBg1KpTgAAADgdlZoWH/++eeVnp6uYcOGXXf+9MTERA0dOlRWq1XPP/98qRYJAAAA3I4KDev333+/Xn31Ve3fv19BQUGaO3euDh48qISEBGVlZSk2NlYHDhzQ7Nmz9eyzz+p///ufQkJC1KpVq5tVPwAAAHDLKnw+RknDhg2Tm5ub5syZo5kzZ2rmzJl52thsNrm5uenll1/WiBEjyqRQAAAA4HZz3bDu5OSk1157Te3bt9eqVau0bds2nTt3TvHx8apSpYpq1aqlJ554Qh06dFCtWrVuRs0AAADAbeG6YT3bX/7yF40YMYIz5wAAAMBNUuiYdQAAAACOQ1gHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAM5eroAgAAtwfPyuVVvpybo8soVanpViVcTnV0GQBuYYR1AMBNUb6cm9pO+NTRZZSqDWNfVYII6wDKDsNgAAAAAEMR1gEAAABDEdYBAAAAQxHWAQAAAEMR1gEAAABDMRsMAAA3GdNYAigqwjoAADdZ+XJuembOfEeXUarWvfYi01gCZYBhMAAAAIChjA7rU6ZM0ahRoyRJ0dHRCgkJUWBgoEaPHq2MjAxJ0pkzZ9S7d28FBQVp0KBBSkpKkiTFx8dr4MCBateunXr37i2LxeKw4wAAAABKwtiwvmvXLq1atcr+75EjR2rs2LFau3atbDabli9fLkkaP368evXqpaioKDVp0kRz5syRJM2YMUN+fn6KjIxU9+7dNXHiRIccBwAAAFBSRob1uLg4TZ8+Xa+++qok6fTp00pNTVWzZs0kSSEhIYqKipLVatWePXsUGBiYa7kkbd68WR07dpQkdejQQVu3bpXVanXA0QAAAAAlY+QFpmPHjtWIESN09uxZSdL58+fl7e1tX+/t7a1z584pNjZWHh4ecnV1zbX82m1cXV3l4eGhS5cuqXr16kWuw8vLo7QO6U/D29vT0SUYg764ir64gn64ir64ir64ir4ASp9xYf2rr76Sr6+vWrZsqZUrV0qSsrKy5OTkZG9js9nk5ORk/zuna/+dcxtn5+J9kXDxYqKysmx5lt/Kv4wsloRitacvrqIvrrpV+6K4/SDRFznRF1fRFwCyOTs7FXqC2LiwHhERIYvFoueee06XL19WcnKynJyccl0geuHCBfn4+KhatWpKSEhQZmamXFxcZLFY5OPjI0ny8fHRhQsXVKNGDWVkZCgpKUlVqlRx1GEBAAAAxWbcmPWFCxdqzZo1Cg8P17Bhw/TUU09p0qRJcnd31759+yRJ4eHh8vf3l5ubm/z8/BQRESFJCgsLk7+/vyQpICBAYWFhkq58APDz85Ob2611AwoAAADc2owL6wWZOnWqJk2apKCgICUnJ6tfv36SpHHjxmn58uVq37699u7dq9dff12SNHz4cP3vf/9TcHCwlixZorFjxzqyfAAAAKDYjBsGk1NISIhCQkIkSQ0bNtSKFSvytKlZs6ZCQ0PzLK9SpYo+/fTTMq8RAAAAKCt/mjPrAAAAwO2GsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGIqwDgAAABiKsA4AAAAYirAOAAAAGMrV0QUAAIDbl2eV8irv5uboMkpVqtWqhLhUR5eBWwRhHQAAOEx5Nzd1Wxnq6DJK1YqQvkoQYR2lg2EwAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKEI6wAAAIChCOsAAACAoQjrAAAAgKFcHV0AAAAApDuqVpC7660VzdIyMhQfm+LoMv7Ubq13BAAAwJ+Uu6urRu/6ytFllKqJLbs7uoQ/PYbBAAAAAIYirAMAAACGIqwDAAAAhiKsAwAAAIYirAMAAACGYjYYAAAAGKVK1Qpyu8WmsbRmZCiuBNNY3lq9AAAAgD89N1dXfXtkm6PLKFXBdZ8o0XYMgwEAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADEVYBwAAAAxFWAcAAAAMRVgHAAAADGVsWP/kk08UHBys4OBgffDBB5KknTt3qmPHjnr22Wc1ffp0e9vo6GiFhIQoMDBQo0ePVkZGhiTpzJkz6t27t4KCgjRo0CAlJSU55FgAAACAkjAyrO/cuVPbt2/XqlWrFBYWpp9++klr1qzRO++8ozlz5igiIkI//vijtmzZIkkaOXKkxo4dq7Vr18pms2n58uWSpPHjx6tXr16KiopSkyZNNGfOHEceFgAAAFAsRoZ1b29vjRo1SuXKlZObm5vq1q2rmJgY3XvvvapVq5ZcXV3VsWNHRUVF6fTp00pNTVWzZs0kSSEhIYqKipLVatWePXsUGBiYazkAAADwZ+Hq6ALyU69ePfvjmJgYRUZGqk+fPvL29rYv9/Hx0blz53T+/Plcy729vXXu3DnFxsbKw8NDrq6uuZYXh5eXxw0eyZ+Pt7eno0swBn1xFX1xBf1wFX1xFX1xFX1xFX1xFX1xVUn6wsiwnu3w4cN65ZVX9P/+3/+Ti4uLYmJi7OtsNpucnJyUlZUlJyenPMuz/87p2n9fz8WLicrKsuVZfiu/6SyWhGK1py+uoi+uulX7orj9INEXOdEXV9EXV9EXV9EXV91OfeHs7FToCWIjh8FI0r59+zRgwAC9+eab6tKli2rUqCGLxWJfb7FY5OPjk2f5hQsX5OPjo2rVqikhIUGZmZm52gMAAAB/FkaG9bNnz2rw4MGaOnWqgoODJUlNmzbVsWPHdPz4cWVmZmrNmjXy9/dXzZo15e7urn379kmSwsPD5e/vLzc3N/n5+SkiIkKSFBYWJn9/f4cdEwAAAFBcRg6DmT9/vtLS0jR58mT7sueff16TJ0/W0KFDlZaWpoCAAAUFBUmSpk6dqjFjxigxMVGNGzdWv379JEnjxo3TqFGjNHfuXPn6+mratGkOOR4AAACgJIwM62PGjNGYMWPyXbd69eo8yxo2bKgVK1bkWV6zZk2FhoaWen0AAADAzWDkMBgAAAAAhHUAAADAWIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHUAAADAUIR1AAAAwFCEdQAAAMBQhHX8f/buPLqmq3/8+PtmllkMGWSQREQSZEKQCBVjomqqqaanWq2hamyV1oNWVUuVGmpIzXPVHKJIhEiQQUgiRJCJhMhgiORmOL8/rHsbbb/P06c/cTn2a62uCjlrfc6+557zOXt/9t6CIAiCIAjCS0ok64IgCIIgCILwkhLJuiAIgiAIgiC8pESyLgiCIAiCIAgvKZGsC4IgCIIgCMJLSiTrgiAIgiAIgvCSEsm6IAiCIAiCILykRLIuCIIgCIIgCC8pkawLgiAIgiAIwktKJOuCIAiCIAiC8JISybogCIIgCIIgvKREsi4IgiAIgiAILymRrAuCIAiCIAjCS0ok64IgCIIgCILwkhLJuiAIgiAIgiC8pESyLgiCIAiCIAgvKZGsC4IgCIIgCMJLSiTrgiAIgiAIgvCSEsm6IAiCIAiCILykRLIuCIIgCIIgCC8pkawLgiAIgiAIwktK9sn6wYMHCQ4Oplu3bmzdulXT4QiCIAiCIAjC36aj6QBqU35+PkuWLOHXX39FT0+PwYMH4+fnR5MmTTQdmiAIgiAIgiD8V7JO1s+ePUvbtm0xNzcHoHv37hw9epQJEyb8reO1tBT/5781smv0XGJ82fync/6/WNtY1kIkmvdP2sLS0qIWItG8f9IWDeub1kIkmvVP2gHA0sLkOUeief+4LcxEW6hYmhg/50g075+2RQNDo+ccieb907Yw1zd8zpFo3j9tizo6+s85Es37q7b4b+2jkCRJqq2ANG316tWUlpYyefJkAHbv3s2lS5f48ssvNRyZIAiCIAiCIPx3sq5Zr66uRqH4/W1FkqRnfhYEQRAEQRCEl5msk3UrKyvu3bun/vnevXs0bNhQgxEJgiAIgiAIwt8n62S9ffv2xMTEUFhYyJMnTzh27BiBgYGaDksQBEEQBEEQ/hZZTzC1VNK1owAAIABJREFUtLRk8uTJjBgxgoqKCgYMGEDLli01HZYgCIIgCIIg/C2ynmAqCIIgCIIgCK8yWZfBCIIgCIIgCMKrTCTrgiAIgiAIgvCSEsm6IAiCIAiCILykRLIuCIIgCIIgCC8pkawLgiAIgiAIwktKJOsaVF1drekQBOGlVlxcTGRkpKbDeCncuXOHR48eaTqMl4JYxOx3NdtCtItQk8gx5EMk6xpSXV2NltbT5j958iQ3btzQcESa9ceHzOv80KmqqtJ0CC+Fqqoqzp8/z+LFi4mLi9N0OBp15coVFixYQHR0NJWVlZoOR6Oqq6tRKBQAlJaWajgazVHdIxUKBXfu3KGwsBClUqnhqISXQVRUFE+ePFHnGK+7jIwMTYfw/018khqgVCrVX6Lly5ezfft26tatq+GoNEuhUFBYWMi3336r/vl1pa2tTXZ2Nvv27ePcuXPA69dDUl1djba2Nt26daNHjx6sXLmSO3fuaDosjXFzc8PDw4Pz58+TkJCg6XA0pqqqSn3vPHToEBs2bKC8vFzDUWmG6h65b98+PvroI6ZPn05sbKyGoxI07cqVK+zevZs6depQUVGhfrl/3Z4hKmlpaWzcuJHk5ORXOmkXyfoLtnDhQqKjowE4c+YM4eHhdOrUibp16752Paqqm0fNm8i1a9fIzMzUVEgvheTkZEaPHs25c+cYPXo0x48fR0tL67W62aoSsq1bt3L16lUKCwv55ptvePLkiYYje7FqjjDdu3ePc+fOsWXLFtLS0jQYleZoa2vz8OFDxo8fz+7du4mKiuLw4cOaDktj0tLS2LBhA8uWLWPWrFl07NgR4LXqYc/NzeXs2bMA3Lx5k++++46tW7dqOCrNcXNzw8DAgPfff5/58+czZswYbt++/dr2sltbW2NkZMSECRM4ceIE8Gq+uLyen54GTZ48GT8/P8LCwnB3d6dnz56cPHmS1NRUtLW1X6vyD9XNo7i4GABdXV1MTU0pKCgAXs0v1P+v2NhYfvnlF6ZOncqCBQtYuHAhkyZNIiMjAy0trdfqhS4yMpJdu3bx2WefMX36dOrXr8+XX36p6bBeKIVCQVlZGR9++CEGBgZ89dVXVFZWEhER8VqWzimVSr7++ms8PDzYuHEjvXr14tatW4SHh2s6tBfij9//goICDAwMsLGxwcnJiaqqKnbv3k1MTIyGInyxlEole/bs4ejRo+zbt49Jkyahp6fHihUrWL58uabDe+FUvejFxcW0bduWGTNmkJyczL59+9S/8zrkGDXP0czMDIVCgYmJCcXFxVRUVKClpfXKtYNI1l+Amkmnnp4et27dYubMmSQkJNCnTx9atGjBjh07KCgoQKFQyD5JrfnAiYuLo3v37uzbt4+qqiqCgoJYtWoVkiS9Fj0Bf3z4ZmVlkZyczM2bNykrKyMkJIQPPviAoUOHUl5ejra2toYirX1/lYh4e3tjbW1N69atGTVqFLdv3+ann37SUIQvxh+//48fP6a0tJRRo0bh5eXFpEmTuHHjBsePH+fevXsaivLF+Kt74b179/Dw8ADgzTffxMTEhGPHjnHx4sUXHd4LJUkS2traPHr0iMOHD5Ofn4+7uzumpqbqZExbW5u4uLjXYgSquroaPT09evbsiampKYcOHaJ37958/PHHbNiwgYMHD7J//35Nh1nraiadOjo6VFdX4+7uTu/evZk2bRp9+/Zl8ODBrFq1CpB/iWnNOS2XL18mIyODDz74gMWLF1NRUaF+iXvV2kF7zpw5czQdhJzVnEh69uxZioqKcHBwwN/fn7lz59KxY0dcXV1JT0/n9OnTBAYGyj4hU51feno6bm5ueHp6cunSJVasWIGvry9FRUV4eHhgbGys4Whrl6ouu7q6mr1795Kfn0+XLl2orKwkOzsbIyMj7Ozs8PPzIzY2luLiYry9vTUddq3R0tLizp07JCYmYmxsjKWlJatWrcLNzQ07OzvMzMw4ffo08fHxtG3bFnNzc02H/NzVvF9kZGSgra2NkZERFy9eRKlU4uDggJWVFfn5+ezYsQMHBwecnZ1fuQfP31HzXhEREUFJSQkNGjTg4cOHXLt2DWdnZ+rXr4+WlhbHjx+nsrISFxcX6tSpo+HIa4dCoSArK4tx48aRlJREUlISlZWVNGvWTP3iVlJSwsGDB3nrrbewtLTUdMi1pua1Ua9ePRo2bEhiYiL37t3Dx8cHe3t7bGxs+O6773BxccHOzk7DEdeOmveLW7du8ejRI4yMjPj6669Zv349I0eO5L333qOgoIDNmzfz1ltvyfJeUZPq/NauXcvKlSvVIwuurq7Ur1+fq1evcufOHQoKCrCzs3tlOgVFsl7LVBfOwoUL2bt3L3l5eSxdupRevXrh7OzM0qVL6dOnjzrx8PLykvWXSUtLi/z8fEaMGEFycjLr16/n3XffJSgoCB0dHQ4fPszJkydp1qwZrq6umg63VikUCvLz85kwYQIPHz7kwoULhIWF8dZbb3Hjxg2ysrIwNDTE2tqat956S9aJOjytvx07dizp6enExsZSr149PD09WbJkCY6OjkRHR3Pjxg3mzJmDo6OjpsN97mqOJi1dupSVK1dy8OBBXF1defToEdnZ2dy5c4eWLVuyb98+HB0dGT58ODo6OhqOvHao2mLhwoXs3LmT06dPU1FRgbGxMSUlJRw6dAgHBwdWrlyJra0tmZmZBAYGyvYl/9KlSyxYsIAPP/yQadOmkZOTw+3bt7GxscHf358TJ05w5coVJk2ahKenp6bDrTWqTo6Kigrmzp3LuXPn8PPzw8PDg6tXr1JUVISrqytNmzbl8ePHsu7kUOUKP//8M8uXLyc7Oxtvb2+aNm3K/v37GTduHEZGRixevBhDQ0O6du2q4YhrR3V1NatWraJ169bA09Vwdu3axebNm+nbty/5+fmkpqbSqVMnTExM2L59OxUVFXTq1Emzgf8PRLJeC8rLy4mKisLMzIw6depw4cIFjh07xubNm+ncuTMNGjTg448/Zu7cudy8eZPt27czZswYWrduLetEHeD+/ft89NFHvPPOOwwdOpSdO3cSHR1N79698fDwwN/fHzs7O8LDw3njjTfQ09PTdMi1atOmTVhYWDB79mzefPNN4uPjSUlJYdKkSRw6dIgnT57QvHlzdHR01CVScrxGDh06xJ49e5gyZQqjRo2iuLiY2NhYAgICcHR05Pjx46SmpjJz5kwaN26s6XBrhepz3bJlC+np6axfv57bt28TExNDt27dqK6uJjY2lm3btmFoaMi8efPUIzNyuSaKi4uJj4/Hzs4OSZL44YcfKCwsJDQ0FHt7e2JiYrCxscHb2xulUkl0dDStW7dm4sSJHDhwAG9vb+rXr6/p03guaq58A097TleuXEmrVq3w8PDAysqKjIwMbt68SYsWLRg2bBhdu3bFxsZGVtfEHykUCvLy8pg8eTIODg48ePCA5cuX8/HHHwOQkJBAYWEhzZs3p3Xr1rJN1CVJQqFQcOjQIcLCwti4cSONGjVCkiTMzMxo0aIFixcvJjw8HGNjYxYuXKjpkGvN48eP+eabb7hx4waBgYHk5eVRUlKifjnx8fHhxx9/xNzcnD59+hAUFET37t01HPX/5tXo/3/FREdHs3PnTmJjY1EqlRQWFqonflRUVNC9e3c6duzIkSNHmD17NqNGjcLQ0FDDUdeOP9YhP3r0iKZNmxIcHMzBgwcZN24choaGfPbZZwBYWFjQrl07GjRogJGRkSZCrjV/NTn0/v37NGzYUP3zzJkziYiIoKCggAkTJjBo0CDq1KmjfvC+KkN2/80f26KkpITDhw+jo6NDnTp18Pf3x9HRkV27dhEQEMDChQtZs2YN9vb2Goq49tSsOY2Li+PYsWPqz3ny5MnUqVOHI0eO0KZNG3744Qe++eYbFixYADw7DP6qKy8v586dOygUCqqqqsjJySEvL4+kpCQA2rdvj4+PD3Fxcdy+fZsPPviAkJAQKioqePvtt/Hx8aFZs2YaPovno2aZx/bt24mLi6Nly5Z89dVXrFy5kps3b2JjY0PXrl1RKpXcvHkTQL1IgVyuCZWacxcqKys5ffo0vr6+TJ48mXr16iFJEiNHjiQoKAhHR0cyMjIoLCxUH/OqTSb8T1RtoXom1K9fn8aNG7NgwQJCQ0P597//TY8ePXB2dmbr1q0sWLCAb775RpMh1xpJkpAkCWNjY5YuXUpCQgLbtm3D1taWEydOkJubCzz9XrzxxhvqUTcLCwtNhv2PiJ71WuDo6EhhYSEJCQmYmpri4eFBTEwMkiSpHyanTp3Czs6OZs2a4ezsrOGIa0fNh0ZiYiJaWlpYWlpSWVlJSUkJGRkZ9OvXj7t377Jp0yZMTEzw8vJi+/btJCYmEhISgra2tix6iFRDtwDr1q0jPT0dXV1d7O3t+fLLL+nduzdGRkZoa2tz7tw53njjDRo3boyhoaHseslqJiLHjh1DT0+PgIAAHj9+zNq1axk2bBgWFhbo6+tz9epVdHV1adKkiazaAH7vGVMoFBQUFKBUKrG1tcXAwIBLly6ho6ODi4sL/v7+bN26lby8PNq3b4+ZmRkgr0T91q1bTJ48maCgIDw9PZk0aRIuLi4EBASQlpZGcnIy/v7+uLu7c+XKFW7cuIG3tzcmJiZcvnyZ4OBgBgwYoOnTeG60tLR48uQJY8aM4caNG5w5c4bHjx/Tq1cvAFatWkXv3r2xsrLC1dUVX19f9bFy+57As2vKnz59mocPH+Lm5salS5fQ1dVl9uzZfPvtt+Tk5DBkyBA6dOjwzJwWubSJ6jufnZ3NL7/8QklJCQ8fPqRhw4bcuXOHvn37Mn78ePXvu7m5YWJiosGIa5fq/hkREcGRI0cYNmwYixYtomvXrtjb2zN79mz1BPQjR44wcuTIVzJRB5GsPzepqalUVlaqvxheXl6kpqZy6dIlzM3NsbGxYdeuXdy9e5fTp09z+fJl/vWvf2FqaqrhyGtHzSHcGTNmsH37dhISEiguLqZ///58//332Nra0q5dOzZu3MjYsWMZOHAg8PStd/To0ejq6srmJqs6jzVr1nDixAkMDQ3Zvn07PXr0oGHDhnzxxRfo6Ojw7bff4uDgwFtvvfWnY191quRUNW/h/fffp7S0lNOnT3P27Fk+//xzDh06xIkTJ+jVqxeWlpa4u7vLrv62ZpIOcPjwYebNm0diYiKJiYn4+vpiaGjI2bNnsbCwwM7OjrZt2+Lh4SHLBASe3i/y8/M5evQo3bt3Jzk5mbi4OHx9fXF3d+f48eMUFhbi6elJ69atadWqFaamphgbG9OqVStZlEalp6eTlJSElZUVOjo6zJ8/Hw8PD+bNm8exY8e4fv06BgYG9OnTh6SkJH755Rf69Omjfuaoris5qdlRcfDgQVatWsX333+Pr68vjRs3ZuvWrfTs2RNDQ0OuXbuGtrY2ffr0wcDAQFbtUV5eri6FPH/+PBMnTsTa2pqEhASuXbtGp06dGDJkCImJiZw/f549e/YwYsSIVzYx/V/s2rWL8PBwevbsSUBAACYmJnz55ZfMmDEDe3t7MjMzycvLY9GiRTRq1EjT4f5jIll/DiIjIxk+fDiHDx/m1q1bZGZmYmFhQceOHTl79ixVVVW4u7vj5+fH9evXUSqVzJ8/n3r16mk69FqjpaVFSUkJGzduxNzcnG+//RZzc3P27t2LpaUl9vb2rFixgj179tC6dWtGjBgBPB3irFevnmxusqoHhlKpZPz48Whra7Ns2TL8/PwoLy9n8+bNTJkyBRcXFx4/foyHhwfjxo0DkFWPelpaGklJSdja2qKtrc3KlSsJCQlhyJAh/PTTTwQGBtKyZUsGDBjAF198wePHj2nfvr0sJwtGR0djb2+PJElER0ezadMmNmzYQFFREQcPHuTdd9+lcePG6uTV19cXKysrzMzMZHVNwNPvu5aWFoaGhjRp0oSLFy9y9uxZZs2axcmTJ7l+/Trt2rWjUaNGrFu3Dnd3d6ytrdHX15dVMgZw/PhxNm/eTNOmTWnUqBGXL1/G1taWtLQ0GjRogI2NDXv27EFfX58RI0bQtm3bZ3a+llNbqKjO6ciRI2RkZHDt2jXeeustDA0NSU9PZ9GiRQQEBDB79mz8/Pz47LPP1MfIpT1Uz8mcnBw8PT1Zu3YtgwYNUi/lqlAoCAsL4+HDhyQnJ3PlyhUWLVqEg4ODpkOvFX+cy7F3715iY2PVI7Jubm4UFxezdOlSJk2aREBAAEFBQa98qbFI1p+Dxo0bU1xcTGZmJr169SIqKoqdO3eSlJREdnY2aWlpPH78mG7dutGpUycCAgJkOXHyjw/P+Ph4Pv/8c3x9fdV16Hp6emzevJng4GAGDx5MYGAgb775pvp4uSxbWbP3NDc3F2NjYzIyMjh58qR6x1obGxvu3LnDli1bGDNmDN7e3ri7uwPyKXFQtcO2bduIj4+nXr16NGrUiFOnTpGdnc3atWsZMGAAffr0Yfbs2fj7+9O/f39cXFyeSUTkIj8/n379+tG4cWNcXV3Jy8vD1NSU+Ph4jh07xvfff8/p06cBaN68ORYWFrItcaiqqkJHR4eKigoiIiJwcHDAycmJU6dOkZOTw8SJE9m1axclJSW0bdsWf3//Z0ZZ5NIWmZmZmJqa0qJFCwoLCwkPD8fJyYkWLVrg4uLCjh07GD58ON7e3uzatQtra2vatm1Lw4YNZffCUvN8VC+mERERJCQk0KtXL+7du8fFixdp3bo1VlZW6nXlW7duzfvvv//McXIwe/ZsUlJSCA4OZs6cObRq1Ypbt25RUVFBq1atMDY25smTJ8THx/Pee+/RrVs3QkJCZFv6oiqhLC8v5+TJk+jp6fHmm29y9epVYmJiCAoKQktLi9atWxMTE0NFRYX6mfqqE8n6/yfVW16HDh04evQoVlZWzJkzh969e2NsbEx5eTm3bt0iIiKC7t27PzOZUE5q3mTj4uJ4/PgxXl5e2Nvbs337djp37oyFhQU2Njbcu3ePiIgI+vfvr24POT10aiba8fHxrFq1iuTkZKZPn05SUhKxsbF07doVY2NjbGxsuHv3Ls2aNXumF1kubZGbm4upqSm+vr6kpqaqewl1dXX55ZdfGDlyJAMHDqSwsJAdO3aovyNyS9QrKyuprKzEzMwMNzc3pk2bRufOndHS0mLx4sVUV1ezbNkyLC0t2bZtG6ampgQEBNC0aVNAXt8PFVXt7cSJE0lLS0OpVBIYGIiVlRX79u3D0NCQAQMGsGbNGjp37qxeylVOydi0adMIDw/n+PHjuLq60rVrV6Kjo0lJSaFNmzbk5+dz4sQJmjdvzooVK7C3t2fGjBno6uoC8rlPqNQ8H9Wfc3Jy+O233xg5ciSWlpYkJSVx/fp19UovAQEBtGrVCpBPJ0dRURHTpk1DX1+f5cuX4+rqSklJCY6OjhgYGKh3rrW2tqa6upqwsDA6duwo2yS9oKAASZLQ19cnIyODiRMnIkkS4eHhXLx4kc8//5zQ0FDu3LlDu3btUCgUdO3alebNm2s69OdGJOv/QH5+PsbGxupJg0qlEh0dHQICAliwYAGVlZX4+fnRuHFjOnTowJAhQ+jVq5f6wSs3NROJbdu28fXXX3P9+nXi4uJ47733yMvLY/v27XTp0gUTExNcXV3p0aOH+oED8nno1Jw8+cMPP7Br1y5sbGzIzs7m/v37TJs2jS1btnDjxg38/f0xNzdXl3vIKSErKytj8uTJHD9+nLi4OJydnWndujVnzpyhoKCA+vXrY25uztmzZ5EkiSVLluDp6SnLdYBjY2NZtGgRx44dw8HBAT8/PxQKBfPmzWPatGnk5eWhVCoxNTUlNTWVXbt2MXTo0Gc2tZHLdVHzGq+srOTHH39UT4pTKpVkZGQA4OnpydKlS/H391cnaSpyaIvCwkKmTZuGiYkJS5cuJSwsjNLSUnx9fenQoQNhYWHk5ORgZWVFcXExu3fvxtnZmS+++AKQ1wuLyi+//EJ4eDjZ2dncvn2bdevWERgYiJOTEwkJCdy8eZMePXogSRIRERFIkoSrq6v6fiuXVXDKy8sZOnQoenp6LFu2DHi6xO/hw4fx8fHB09OTpKQkoqKiSExM5Pvvv2fQoEG0b99ew5HXjosXLzJgwADs7OywtbVlw4YNDBo0iA4dOrB9+3YCAgLw9PTkjTfe4LPPPqNBgwY0a9ZMFtdCTSJZ/x89efKEcePGYWFhgYmJiXoFj6qqKkxNTXFzc2PJkiXY29vTuHFj9cPJzMxMdjdXFdV5LVq0iKKiIpYuXYqLi4t6wtSUKVP47bffCA8Pp1evXhgYGKi3RZZLm0iSxM6dOwGwtLSkpKSErVu3sn79eoKCgnBwcODMmTMoFApGjhzJ559/TosWLbC1tZVdjeWtW7eYPn06rq6uTJ06lYMHD2JtbU3z5s1xdnbm2LFjmJqa0rZtWywsLLh58yZeXl7qWn052bdvHytXrmT48OGUlZURGhrKkCFDaN26NRkZGaxbt45ly5aRnp7O+fPnuXjxIrNmzcLLy0vToT93f+z1VCgU7N69m/z8fEJDQ8nJyeHw4cPcv3+fdu3a4eTkRNOmTWU3ylJcXExISAheXl7MnTsXgPPnz3PhwgUSExMpLS1l9OjRbN68GTMzMwYOHEhISAjdunUDnu0QkIuvv/6aqKgofHx8yMzMxMHBgQsXLnDixAny8/NxcXGhurqali1bYmFhgZWVFYGBgc9sCCaX+6eOjg6mpqZERkbStm1bNm7cyMGDB3FwcCAqKor4+HiKiorUbTFq1Ci6dOmi6bBrTXl5OYcOHVKXySYkJKBUKlmzZg0jR44kJCSEqVOn0qdPH3x9fWnRooXsln0GQBL+turqakmSJCkhIUFydXWVOnXqJEmSJJWXl0uSJElVVVWSJEnS3r17JV9fX+nWrVuaCfQFUZ2vSv/+/aWQkBD1v505c0aaOXOmtGnTJkmpVEp79uzRRJgvRHl5uZSamipVV1dLSUlJ0pMnT6ROnTpJ58+flyRJkh49eiT98MMP0qhRo6Tr169LRUVFGo74+auurpZu3rwpubq6Snv37lX//bvvviv961//kj799FMpLi5OSk9Pl6ZOnSpt2bJFKisr02DEtSs0NFTy9/eXcnNzJUmSpKysLGnYsGFSaGioFBMTI0mSJI0cOVKaPHmy+pgnT55IkvTn79arrrKyUv3nH3/8UVq/fr3066+/Svn5+dLq1aulEydOSJIkSbm5udJHH30k3b9/X/37cmsLSZKkBQsWSCNHjpQkSZIWLVok9e3bVzp16pS0cuVKKTg4WIqLi5MuXLggjR49WiooKFAfJ8e22LNnjzRx4kT1uRUXF0vl5eXSvXv3pAMHDkg//vij1Lp1a6lr165SVlbWM8fKsT1UQkNDJQ8PD+mDDz5Q/939+/el48ePS4MHD5amTJkiFRYWajDCF6OkpER67733pNGjR0urV6+W5syZI7Vv316KjIyUJEmSrly5Ig0fPlydh8mV6Fn/m1S16VVVVZSXl5Oenk5mZiYffvihumdd1dvRrFkzGjdu/MzEMDmRakyezMnJ4cqVKxgZGTFkyBDWrVtHaWkpfn5+WFpaUlFRQXR0NK1atVLXFcqNJEno6Oigra3Nr7/+ym+//YajoyM2NjacPXsWV1dX6tWrR2pqKkVFRWRmZuLr60udOnVkNbqgUCgwNzfnxIkTSJLEG2+8wYwZMyguLmbEiBE8ePCAb775htGjRwNw9epV2rRpI8vJ1qWlpcTHx6Orq0vPnj25d+8eY8eOxcXFhZycHM6dO4dCoeDTTz9lypQp2NjY4Obmho6OjmyG8wGUSiXa2trq85k6dSqlpaUEBwczZswYWrVqxdtvv01MTAx5eXksW7YMZ2fnZ3oK5fL9qKldu3bExMQwffp0GjVqxNq1a3FwcMDT05P09HSMjIzo3LkzXbp0Ua+rD/Jsi8jISIyNjWnfvj3Hjh1j586dfPvttxw/fpzi4mI++eQTbG1tefLkCWVlZbKcZPxXvL29KSoqIi8vj759+wJQp04dnJyc6N+/P126dHnlVzj5Kw8fPiQuLk69AZ6+vj4mJibcunWLR48eYWdnh4ODg3pn1sWLF+Pn54e/v7+GI69dIln/G1S16aWlpZw/f566desyatQoysvLmTlzJiNHjlQ/jCoqKtDW1pbtRkfw+w3y6NGjfPnll2RmZnL48GEeP37MjBkzmDhxIi4uLjRt2hRLS0sCAwNlswX4X1EoFNy+fZutW7fSsmVLCgsLuX79OtbW1lRWVrJw4UKysrKIjo5m8ODB3Lhxg27duqGlpSWrh40qMXv77beZM2cOK1aswN/fn4ULF+Lk5ES7du1ISUnB2tqabt260a5dO+rUqaPpsGuFrq4uVlZWlJSUsHr1arZu3cq0adN4//336dq1KykpKWRlZfHGG28wbNiwZ8pe5HJNlJeXs3jxYuzs7DA3Nyc/P59bt24xa9YsVq1ahbOzM2+99RaFhYWUlJSQkpJCixYtGDt2LCDPSbUqWlpa+Pn5kZiYiK2tLQEBAcDTnRbXr1+Pq6sr7u7u6jIPubYDPD3nxYsX89tvv7Fnzx68vLzo0aMHffr0ITY2liZNmuDv709RURFFRUW0adNG0yG/MH5+fpw8eZKoqCj1fB5Vx6FcXuhrKisrY8CAAWzcuBGlUom9vT2GhoaYm5tTUlJC9+7dOX36NNbW1pSWlqKrq4uPj4+6A0jO5Pdp1wItLS3S09MZMmQIO3fuZO7cucybN4/x48fj5ubGBx98QFxcHMXFxc9MmpSbqKgoUlJSALh37x7btm1j8eLFLFu2jE8//ZS9e/eSkZHBTz/9xEcffUR2djZmZmayqzmFP29fraenx8mTJ9HV1WXgwIGUlZWRlZXFsGHD1Bsd7dixg+LiYu7fv095ebkstsCWJIm4uDjvE9s+AAAgAElEQVTgaRuoEvadO3dSVVWFh4eH+ncfPnxIbm6uOvGQW4/6gwcPgN+vDTs7Ozp37oy9vT2urq4EBQUBT2tSHR0dqaqqorKyUr0KUFVVlWYCrwVXrlwhNjaWkSNHYmpqysWLF5EkiRMnTvDOO+9Qt25dFi5cSGJiIl9//TUhISFMmTKFYcOGAfKaQPlXn6skSZiZmTFv3jyio6PZu3cvSqWSkSNH4uHhQf/+/YHfd2iUMx8fH1atWkXfvn3Zu3cvkydPpk+fPrRs2VI9Yglw+/ZtUlJSUCqVsrh3/h36+vp8+eWXpKam8t133wHIbr5CTQYGBkyePBlra2siIyM5evQoP/74I/Xq1SM5OZnCwkI+/PBDEhMTadu2LaNGjVJvpih3omf9v5AkidLSUhYvXky/fv3U22BnZGSQmJjIvHnz2Lt3LwcPHiQwMFC2Gx3dvXuXVatWqYehAHbs2MHQoUOpU6cO9erVo6ysjMTERIYPH46Tk5Osy15UD1BVyYetrS3GxsYcOnSIfv36oaWlRVJSEllZWXTt2pXU1FRCQ0NJSUlh6dKlGBoavvIPYUmS2LNnD0ePHsXIyAh7e3u0tbWpqKjAzMyMZs2aMX78ePr27UtZWRnjxo2jS5cu6iFduZAkidu3bzNkyBCaN2+OjY2N+hqpV68epqam3L59m+TkZNq0acPu3bvZsmULH330ETY2NuoeMrn0lG3YsIGFCxcSHx/PuXPnqKioYM2aNQwaNIj79+9z8eJFVq5cCcCWLVto3Lgxbdq0+ctl+151qpKmwsJCMjIysLCwUI+oSZKEubk5Li4ufPrpp2zatInhw4fz4YcfAvJ6YflvLC0tad68OaWlpejr66Ojo8OsWbMoKSlh8ODB6Orqcv36dQYNGkSDBg1em3YBMDQ0xMfHB2tr61d6B86/y9nZWb2D8+DBg7lw4QIJCQm4uLgQERHBoEGDqFevHq1bt5blpnn/F5Gs/4WaO2QpFAr09PT49ddfcXd3p0mTJpiZmaFUKjl79izBwcH06NGDgQMHPrO8mJxUVlZiYmJCw4YNOXHiBKWlpTRr1oyCggLu3buHu7s7WlpapKSkUFJSQmBgIE2aNEGhUPxptzE5UCgUVFRUEB4eTkpKCkuWLMHd3R0DAwMePHhAy5YtcXFx4f79+9jb29OkSRPc3NywtLRk3Lhxshh9USWjTk5OXL16lfT0dCwtLalfvz5aWlpUV1fj5OSEkZERY8aMISoqivfff58hQ4ZoOvTnrrq6GjMzM8rKyti2bRvt27fHxMREnWxZWVkBkJSUxLJly8jNzeWHH37AxcVFdqUeCxcu5Pz586xZs4ZevXoRGhrK4MGDqa6uZv/+/UyfPp2YmBgOHDjAvn37KC8v55NPPpHdKIuKQqHg0qVLTJgwgZMnT5KdnY21tTUWFhbqz71Ro0bY2toSEhJCSEgIIJ/1wv8X2dnZhIaGsmbNGg4cOECdOnX48ccf1fdLT09PLCwsNBylZtSvX/+1SNRV3N3dycnJ4dSpUyxbtoxbt25x+fJlwsPD6devH25ubrKs1/9PRLL+BzUniu7Zs4c7d+7QqFEj7ty5Q3l5OQ0aNKBu3bpIksSZM2fo2LEjhoaGskjA/i9aWlrcvHmT77//HqVSSVRUFNbW1hgaGnLz5k0OHToEwE8//cSgQYNwcnJSP4jk8sBRJVXV1dVUVFSwceNGMjIyGD9+PPXr1ycyMpIrV64QHh5OvXr18PDwwN3dHUdHR+Dp0KWcbraqzzc2NpYjR46QlpZGWVkZDg4OmJmZqXsUvb290dXVZdiwYQQGBmo46uev5mTQrKwsjh07RkxMDMHBwejp6an/3dLSkocPH6JQKFi0aBFmZmaySsgqKysZMWIEderUYfny5RgZGXHt2jUeP37MwIEDadq0KUlJSSQlJfHdd9/h6uqKk5MTH330EXp6erJ8qYenG8StXr2aWbNmMWDAACIiInjw4AE2NjbPbGDj4uKCg4ODurxDjm3x36g2DHN1daV169a8++67wJ+3lxfkT6FQ4Ofnx5EjR4iPj2fixIl06dIFIyMj9fyO141I1mtQPViVSiVTpkzh8uXLHDp0CF1dXaytrUlJSSEiIoLy8nK+/fZbOnToINuNCGoOwVZUVDB79my6dOnCzJkz1avA2NnZ0b59e/Ly8sjMzOS9996TZUIGvyenCoUCbW1tHjx4wK1bt8jMzGTgwIF4eXmho6PDmTNn0NXVJSAgAG1tbVn1mv5RQkICc+fO5ZtvvsHBwYH8/Hyys7Np2rQpderUUU+2btWqFdbW1poOt1aoPt9PPvmEnJwcpk6dSkREBNevXycwMBAtLS0kSUJXVxdnZ2e6du2qXlVKTrWnhYWFrFmzhq5du+Ll5cXu3buZNWsWeXl55OTkUFFRga+vL2FhYRQWFtKtWzf1i6yc2qJmYllRUUFYWBgHDx7k3XffpVGjRpiYmHDmzBnKy8tp1KjRnyZYvw416v+JkZERdnZ26lJLOV0bwv9GR0eHdu3asWLFCnJycggICJDl/hN/l0jWgdTUVBISEmjSpAkPHz5k5cqV6OjosGTJEry9vdmxYwctWrTAx8dH3WPUo0cPhg4dqunQa0XNG+T+/fuxs7MjOjoaZ2dnXF1d8fT05MyZM0RFReHl5cWAAQMICAjAzs5OdnWWNcsUIiMj+fbbbwkJCcHR0ZHHjx+TlpbG/fv38fHxoWnTpnh5edG7d2+MjIxk1Q7w5xraS5cucfv2bUaMGIGrqytaWlpERkZSXl6Oq6urrEebaqqsrOTQoUNMmDABDw8P+vbty8qVKykoKHimFlu1soeclmZUMTQ0pFWrVixevJjTp0+Tnp7OzJkz6dmzJ8nJycTExLB+/XokSaJfv37qZdlAPr3INe+bqamp6Ovr4+TkxJMnTzh27Bg9evTAzs6OJ0+ecPz4cVxdXWVbOvm8yOXaEP4ZQ0NDfH19sbGxkdXI9D8hknUgLy8PCwsLDA0NuXv3LlFRUaSmptKzZ0/1pLk9e/bQpEkT3nzzTdq3b0+zZs00HXatUd0g165dS1hYGB07duTevXuUlJRQv3596tati5WVFTt27FAPW8ptF0748/CrkZERu3btIisri/bt2+Pk5MTFixc5efIkCoUCd3d3rK2t0dfXl91Li6pkQ6lUkpaWhrm5Odra2iQmJmJoaIiDgwP29vbs3buXnJwcmjRpQoMGDTQd9nNX8+Xt0aNH6mvk8OHDNG7cGFtbW3R1dalXrx5z5sx5phRKRU7XRU2WlpZYW1uzfv16vvjiC9q3b4+NjQ1BQUH069cPa2tr/vWvf8m2d0w1kfTdd9/l4sWLHDhwgPLycvz9/cnNzeXs2bMEBgbSrFkzHB0dadGihaZDFoSX3utWr/9/ea2T9bCwMIqLizEzM8PBwYHg4GCCg4Px8fHhzp07pKWl0a5dO5o2bUpWVhZpaWkEBAQ8s8WxnNRMMK9cucLHH3/M6NGj8ff3p6qqigsXLhAdHc3Dhw/56aefCAkJkeWEQfh9bX2lUsnXX39NZmYmjRo1IigoiNWrV6OtrU2LFi3Q1dUlPT2dVq1a0bhxY/XxckrIVD3BGRkZfPTRR+Tm5qprb01NTbl06RKPHj3i0aNHnDp1irFjxz6zcYmcqD7XnTt3smrVKo4fP46ZmRlaWlr88ssvODs7U79+fc6cOYOJiQn9+vV7rVYscHJyQldXl9DQUHWNqWo5T1dXVywsLGT3IgtP7xdlZWXMmzcPPz8/Zs+ejampKTk5OeTn59OtWzcOHDhAUVERPj4+NGzYEJD3WvKCIDw/Cul1WbD0Dz777DPS09Np1KgRWVlZhIaGsm3bNs6dO8fixYtJT08nLCwMZ2dn9UQXOd9YVedWWFiIJEnUq1ePDRs2sHLlSs6cOYOenh5XrlxR/+fq6sqAAQMA+a5ckJeXx6RJk2jZsiUZGRnY2NgwZswYcnNz+fDDDxk8eDARERFMnz79mR0X5aK8vBx9fX3gaU3yF198wXvvvYeJiQmjR49m4cKFNGjQgCtXrrB//34qKysZM2YM7dq103DktWv79u389ttvrFq1ipkzZ5KXl8fWrVtZvnw56enpFBQUYGpqyg8//KAeZZHj9+M/mT9/PsnJyWzfvl3TodSav/pcp0yZQu/evenUqROVlZXs3buX2NhY5s6dS0pKCjY2Nup6bEEQhL/rtetZLyoqYvr06RgbG7Nq1Spat27N9evXuXLlCpMnTyYyMpKYmBjefvttqqqqiIyMxNHRkYYNG8o2UYenPYYxMTFMmjSJpKQkcnNzGT16NBkZGaxatYrBgwfToEED3Nzc8Pf3p3nz5oC8EnWlUqnuUa+qqmLVqlW4u7szadIkYmJiyM7OpqysjODgYNq2bcvdu3cZPnw4HTp0AOT1MrdixQr27NnD7du38fLyQqlUEh8fj0KhYMWKFYwdOxYnJyfCwsIYNmwYQUFB9O7d+5nRBTkoLS1l9erVZGZm0qBBA4yMjLhy5Qpdu3bl6NGjpKWlsWDBAg4dOsTgwYPp2bMnnp6ejBw5Eh0dHVl9P/4Xfn5+hIWFYWJigpOTk6bDee5qfq4xMTHk5+djY2PDhQsXMDAwwNbWFkNDQ+rXr8+RI0fo2bMnjo6O6lWA5HKfEAThxXitkvXy8nKGDh2Kvr4+S5YsAZ5OYLhy5Qq6urq0adOGnj17snnzZm7dusWAAQPw9vbG1dVVw5HXvvPnz7NkyRIWLlzIgwcPOHbsGDo6OkycOJF9+/Zx8OBB9WY2NVcskMtDZ82aNWzZsoU1a9bQokULrKysuHPnDiYmJqSlpWFtbY2fnx8rVqwgLy+PLl260KlTJxo1aqRebk0ubTF79mxSUlLo2bMn//73v2nZsiUODg5ER0dz5MgRZs6cSefOnblw4YJ6rwE9PT3ZlYfdvHmTCRMmUF5ezrVr14iKiiIkJIRDhw6xfPlyGjZsyKJFi6hbty7z5s3D09MTGxsb6tevD7zeK1no6OgQHBxM06ZNNR3Kc1dzgvAXX3zB/v372b17N0ZGRrRo0YIDBw6Qm5tLZWUlixYtwtnZWb17LcjnPiEIwovzWnX56Ovr88EHH5Cbm0tycjIAN27c4OTJk9ja2qp/b/HixZw/f57y8nKcnZ01FW6tqqioeObna9eu0apVKxwdHXnw4AH+/v5ERUURHR3Nli1baNiwIVVVVbLqPVb5/PPPOXfuHJMnT2bSpEnqzRbefPNNOnfuTHh4ON7e3nTp0gUrKytsbW2pW7eu+ni5LLdWVFTE+PHjqaqqYtOmTfTu3ZsRI0agr6+PgYEBPj4+eHp6EhsbS0JCAqtXr8bHx0fTYdeKU6dO8cknn/D222+zbNkyunXrph41GDt2LFpaWtjb2/P48WMOHDjAkydP/rSyx+uaqKuoSqiqq6s1HMnzpVAoUCqVbNq0iaqqKvbs2cOaNWv4+eef0dXVVY+q7N27l4CAAGbOnAnAa1pxKgjCc/Ba9awDNG3aFKVSycqVKzE0NGTp0qUMHDiQ/v37A0+XYTM1NaVfv36YmZlpONrnT7X2tba2NpIkkZKSQsOGDTE2NsbKyopz585hZ2dH37592bRpE+fPn8fLy4uhQ4eqt8mWk7Nnz3Lu3DnWrFlD3bp1MTExobi4mFOnTmFlZUVBQQFxcXEYGRnx3Xff4enpyfjx49XrZ8ulPVSjTnp6eixbtgyATZs2cfjwYZo0aYK7uzvNmjXDzMyM1NRUYmJi6Nq1KyNGjNBw5M9fZGQkn376KTNmzKBXr14AbNu2DT09PZo3b46ZmRlt27Zl27ZtnD59mvj4eObPn4+Dg4OGI385yeE7UvO7XlFRQW5uLjt27KC4uJigoCDs7OzU8xR69OjBm2++SWBgIG3atAHExj6CIPz/ee2SdQBvb29u3LjB4sWLWbJkCUFBQVRVVQG/94bJsVesrKyMWbNmUV5eTtOmTRk2bBgHDhwgMzOTZs2a0axZM2bOnEm3bt0wMDDg+PHjTJs2TbYrewDcvXuXq1ev4uzszPHjx1m/fj2HDx8mKiqKy5cv4+XlRXV1NefOnaNdu3aMGzcOkFetPjwtWzA1NSUyMpK2bduyceNGDh48iL29PRcuXODXX38lMTERJycnhg4dSlBQkGyX4EtNTQXAw8MDXV1dxowZw+XLlykuLubw4cM8ePAABwcH+vfvT7du3ejTpw9WVlaiFlmman7X4+LimDRpEoMHD8bNzY1r167x8OFD3NzccHd3Jzs7mwMHDtCrVy90dXVRKBSyXFdfEIQX67VdDaasrIwpU6bQsGFDXof3laKiIiRJIioqiv3796NQKOjduzft27fn22+/xdHRkc6dO3Pw4EFu3brFrVu3mDp1qrrWUk69yDWlpaXx888/c/36dfLy8hgzZgyurq60a9eOf/3rX/Tt25fevXtTUVGh3uRHbol6TT///DPff/89AQEB/PTTT8DTaychIYF169ZhZmbGN998g7m5uYYjrT3V1dXs3LmTuLg44uLiGDNmDO+88w7Z2dlERERw/vx5jh8/znfffcebb76pPkau14Tw1IYNG0hJSSEpKYk6deqwf/9+wsLCOHv2LG3atKF3797A0/X3X6flOgVBqH2vbbIOUFBQwKhRowgMDOSTTz7RdDi1ZvPmzYSHh1NWVoa3tzcNGzZk7dq1hIaG0qJFCxISEtixYwe+vr40btwYpVKJra2tejMXOSXqpaWlGBoaPpNcFRYW8ujRIywtLdV1tvB0omWnTp3o3Lmz+u/k1Bb/l/nz53P16lU2bdr0p3+T+6RJ1ef76NEjdu3aRWJiIuPGjcPNze2Z37tx44YsVzkRfrd8+XImTJgAQGxsLPPnz+fnn3+mQYMGTJo0ierqapYtW8bGjRu5ePEi77//Pu7u7oB4eRME4fl6LctgVAwNDfHx8cHa2lq2O2R99913xMbGMm/ePEJCQmjSpAk+Pj4UFxcTGRlJUFAQ9vb2SJLE4cOHad68OR06dKBu3brqYX25JKcXLlwgNTUVR0fHZ5JOAwMDjIyMiI+Pp7i4GCMjIz777DPu37/PBx988MwqJ3Jpi//Ez8+PkydPEhUVRdeuXYHfa27lloD88eVLoVBQXV2Nvr4+1tbW3L59m+TkZOrVq/fMjqzm5uYoFApRiyxTSqWSoqIiXFxcACguLqagoEA9ktKjRw8WLlxISUkJ7733Hubm5s9Mtn4d7hOCILw4r3WyDvLeyjY/P58DBw7www8/0LBhQ0xNTalfvz5GRkY4ODiQnZ3NiRMn6Ny5M87OzlhZWT2zoY3cHjhXr14lIiKCQ4cOYW5urn5JUSgUaGtrs2XLFsLDw9m3bx8WFhYsXbpUvVa23NriP9HR0aFt27asXbuW3Nxc/P39ZZmQ1uz9fPTokfo6UDExMcHc3Jxr166RkpJC06ZN1eUNqutBju0iPJ2z5OzszLx58zh9+jTdunVj/vz5+Pr6YmVlBcDDhw8JDQ2lUaNG6k3RXoeRN0EQXrzXugxG7s6dO8fy5cvZvHkzlZWV6OjoUFVVRXV1NWvXrqVx48aEhYVhb2//TBmQ3IZwVedTVVXF8OHDycrKYtmyZeqeMFUvu1KpVPeoqXYZlHvZx3+SlpbGgwcP1CtayEnNpGrNmjVcvnyZiooK3nrrLXr27PnM70ZFRZGens4777yDgYGBJsIVXrD09HQ2bNjAu+++y8cff8yMGTNQKpXMnj2bjz/+mJycHHJycmjbti2XL19m7ty5IkkXBKHWyCcjE/7Ezs6OrKwszp8/j46OjnqdX11dXe7evUtMTAwjRox4ZsMOkE9voep8tbS0KCkpobq6mtmzZ9O/f39OnDjB5cuXgd9X/tHR0cHY2FidqKt2M31dNWvWTJaJekZGhnqVjh9//JHLly+zaNEiqqqq2LVrF2VlZcDvexEEBgYyevRoDAwMxFrZMqVaDUy1JryBgQGlpaXUrVuXqVOnMnv2bJo0acLChQspLy8nPz+fuXPnUlZWhoGBgUjUBUGoVfLIyoS/1KBBA4KDg9m5cydZWVnPDPNraWnRvn172rRpg6+vr4YjrR2qB2hYWBgTJkzg+++/JyYmhnHjxlFYWKjeJrywsBD480uKXF5ahKckSWL//v1MmzaN3NxcFAoF+vr6fPrppyxduhQ9PT2+//571q1bR1lZmXr1n5rHi6RMfiRJUt8XMzMzATA2Nubhw4dcuXKFN954g1GjRjFmzBgcHBwYNmwYrVq1YsGCBZw6dYrx48drMnxBEF4DIhuRMV1dXQYMGICBgQGzZ88mKSmJ27dvM3fuXLKysvD399d0iLXu0KFDbNq0ia+++gpdXV1CQ0PR0tJi5MiRXLt2jbFjx7Jz507Z7bIo/JlCoaBjx4506tSJBQsWUFVVRVZWFsHBwRgYGLBixQrq1q3L2bNnKSkp+cvjBflRjbKkpKTQr18/fvnlFwDeeecd1q1bR3l5OSNGjKBdu3ZERkYCYG9vj5eXl3o5U0EQhNokatZfA/n5+axbt47Lly9Tt25d6tevz5dffgnIrz79jzXmu3fvpkmTJly/fp39+/ezYMEC4uPj8fb2Rltbm2vXrj2zNKMgbxcvXqS4uJgzZ86gr6/P2LFj6du3LyNGjGDYsGH8/PPPhIWFsWHDBkxMTDQdrvACKJVKxo4dy+jRozE3Nyc8PJxz584xcOBAkpOTee+997CxsZHdvVIQhFeHSNZfI2VlZZSVlak3tJHb5ElVmUJZWRmlpaVYWFiwa9cu5syZQ5cuXVi2bBkAEyZMYNy4ceo1kUF+bSE8VfNzraioYPXq1RgaGtKuXTuWLFlCYGAgAQEBTJkyBSsrK0pLS1m4cCGWlpYajlx4kXbt2kVoaChr1qzBwcGBo0ePsmvXLs6ePcvs2bMZOnSo+ndF0i4Iwoum899/RZALAwMD9aY/cpw8qVAouHHjBh9//DHW1tY4OzszePBg+vXrpy5zOXr0KDdu3Hhm8yNAdm0h/Pka19XVpW7duty8eRM3NzfeffddfvrpJ+zs7Pj1118pLi6W7Yus8Gdnz57FxMQEDw8PBg4cSEFBARMmTGDr1q306NGDli1bkpiYSMuWLZ85TiTqgiC8aKJnXXil1ezlio2NJSIiAl9fX8zNzTl27Bi6uroMGjSIOXPmYGBgoF7F4Y8PYEE+lEolv/32G61atcLS0pKvvvoKhULBRx99hIGBAUOHDmX69On4+flx8OBB1q1bx7Jly7C3t1dviiQSMvn54wvYF198QUlJCVOmTKFx48bA01G3yspKfvrpp/94rCAIwoskknXhlVUzqcrPz1ev8nHy5EkAzpw5w7Fjx3Bzc2PIkCGUlZVRVVWFkZGRSMhkTKlU8vXXX1NRUYGVlRVdu3ZlxYoVmJqa4uDgQIMGDdDT0yMkJES9M2WTJk00HbZQi2om27/++ivu7u40a9aMmTNnYmxszOjRo7G0tGT79u2sWrWKGTNmEBwcrOGoBUEQnhLJuvDK++abbwD44IMPCA4OZuTIkXz44YeUlZURGRnJr7/+yujRo/Hz8wNEzalcqXaaVSgUXLhwgfHjx9O8eXN+/vlnHj58SG5uLnPmzOHevXvY2NiwefPmZ44XSzPKi+rzVP3/7t27TJs2DUNDQyorKwkKCqJ3795MnjwZV1dX7OzsiIiIYOzYsWLkTRCEl4r2nDlz5mg6CEH4X6lq0OfPn096ejpjx47FxsaG9u3bM3XqVNzc3HBxccHCwgIPDw+8vb3Vx4qETH5UPacKhYL8/Hyqqqpo164dly5dQktLC0dHR2xsbOjevTsuLi4kJydjbm6uLn8AcV3IjerzVCgUKJVKvvrqK7p3786HH35IeHg48fHxWFtb8/bbb5OSkkJ0dDSDBg36f+3de3DNd/7H8efJ/eoel0RKxUooUUFcNoIIUiLBqq2W0GW3SqxLti5rKm7tGrTGPTvUpWU1gpqgTNyCsG6rrERaHVZE2qREIuTkck6S3x/G+TW01aoSx+sxY4Z8P9/v+WSS8X2d93l/Px86deoE/P+bPxGRp00PmMoz496HQAaDwVIZb9myJWfPnuXKlSs0aNCAFi1asHDhQsaMGcOuXbvw8fGhVq1agCrq1uxei8PChQu5cOECAQEBREdHc/v2bTZv3kyjRo1o2rQpzs7OdOvWjS+++EI9yFZsy5YtZGZmUrduXXr37o2rqyu5ubn4+/uTmJhIUFAQjo6OrFixgokTJzJp0iRKSkpwdHS0VOL1f4WIVBUK6/LMuFflSklJISUlhfr16zNw4EAKCwvZvn07Xl5e/O53v6NPnz5cvXqVwsLCSufr5mvdFixYQHZ2NvPnzycrK4sbN24QFhZGSUkJixcvJi8vjxkzZvDyyy+zZ88e6tev/7SnLL+B999/n7S0NMLDw7l69SomkwlnZ2diYmJwcXHh6tWrjB8/npMnT2Jra8vmzZvp3LkzDg4OgD5hEZGqRz3r8kzZtGkTn332GRMmTGD58uW4u7sTFxdHbGwsZWVljBw5khdffNEyXn3Iz49169ZhY2NDfn4+OTk5pKenk5eXx969ezl+/DjFxcWEhoYCsHXrVv7whz885RnL47Zt2zYOHTrEokWLsLGxIS8vDwCj0UjNmjU5dOgQixcv5rPPPuOtt94iPDycwYMHP+VZi4j8NFXWpUq7P2x/++23rFmzhv379wMwduxYLly4wIwZMxgxYgSpqamVwrqCuvX5sTdgDRo0IDk5GVtbW8LCwpg9ezZTp04lOzuboKAg4P9boRTUrVNOTg6NGzfGxsaGpKQkUlJSOH36NA4ODvj6+jJ69GjL6lA9evSwBHUtzSgiVZkq61Jl3X8DLS8vZ9SoUeTn51O/fn1iY2OpUaMGw4YNY9OmTdy6dcvSny7Pj9LSUksLQ3l5OWazma+++ooTJ8Ht9WMAABHiSURBVE6QlJTE6tWrqVat2lOepTwJZ86cYdy4cXh7e3P58mUGDRpEs2bNaNKkCR999BEjR46kZcuWZGZm0qhRI0DPsohI1afKulQ5ly5dIj09nfDwcDIzM4mLi6Np06b4+fkxfvx4Jk6cyIwZM6hXrx579uzBzs6OkpISy+6Tuvlav+3bt5Ofn8+IESNwcHDg9u3bvPfeewQFBXHp0iW+/vprDAYD69atw8XF5WlPV56QgIAAVq5cSXp6OkFBQdStWxd7e3vLcUdHR2xsbCxBvaKiQv9XiEiVp7AuVc61a9eYOXMmJpOJ/fv34+fnR2lpKUuWLCE0NJRJkybx9ttvExISwtmzZ5k+fXqlQKabr/W5v/XlzJkztGzZEoDc3FzGjRtH27ZtCQ8PB8BkMllCmlocni/+/v74+/uTnZ1NWVkZ9vb2TJ8+naKiIl544YVKY9UmJyLPArXBSJXx/Yp4QkICCxcuZPDgwcTExGA2m/nvf//LokWLWLJkCZmZmZSUlODl5YWnp6ceJLVi9362BQUFbNiwgcaNG5OTk4PBYGDEiBHk5uaSkZFBQEAAAGazGTu7u3UIfcryfMrMzGTt2rWkpaXh4OBA/fr1WbBgAaCHzkXk2aPKulQJ369+VlRU8Oqrr3L58mU+//xzYmJisLOzo0mTJnh4eHDz5s1KOwwqkFk3g8FAXl4eZWVllJSUsHbtWkwmEwUFBdja2tKrVy9LW0NZWZklqIM+ZXleeXt7M3r0aC5dugRg2ehIn7KIyLNIlXV56r4ftqdNm4bBYCAsLIyAgAAWLFhASUkJ8+bNIy8vj7/85S/ExsZaWiDEOt2rfpaXl2M0GunQoQMLFiygT58+GI1Gjh07xvr16y2bYtnZ2bF69WocHBxUNZUfpKAuIs8qhXWpEvLz83nnnXdo3rw5ZWVl/Oc//yE6OhpfX1/GjRtHQUEBTZs2pV27dkRFRT3t6coTcm9Xyd27dzNlyhQ2b96Mn58fp0+fZvbs2SQmJnLnzh3s7OxwcnJ62tMVERF57PQZsTwVN2/exGg0Wv6dnJyMh4cHkyZNolq1ajg5OZGUlEReXh7vvfceDRs2JCoqyhLU9R7T+iUkJJCUlERxcTGvvPIK0dHRREVFUVhYyEsvvYSTkxOFhYW4ubnh5OREeXn5056yiIjIY2c7c+bMmU97EvJ82bBhA0uXLiU+Pp6cnBwCAwMpKSnBYDCQm5uL0Whk+PDhrF69mtTUVJo1a8aoUaPw9vYG9ICYtSovL6/0c01OTiYtLQ13d3e8vb1p164dR44cYevWrZbNbNq0aWMZr98JERGxRnrAVJ6oBQsWkJqayty5c7Gzs6OgoICKigpatWqFv78/kydPJjg4mMaNG+Pp6Unbtm1p27atZdMbUCizVjY2NqSnp7Njxw58fHwYO3YsS5Ys4eDBg7i6uvLyyy8TFhbGqlWryMjI4I9//COgN28iImLdFNblicnJySEjI4MVK1bg6upa6djt27e5efMm9vb2fPvttwwfPpwmTZrw1ltvAQpkz4P9+/ezZMkSIiMjWb9+PdevX+ftt99m7ty5xMfH88knn3Dnzh02bNiAl5eX5Tz9XoiIiDVTz7o8MVeuXOHWrVu4urpiNpuBu60PpaWlrFu3juvXrxMWFobJZKJLly7ExsZaxiiQWbeioiJ27drFvHnz6Nu3Lw0aNGDr1q3s3LmTKVOmEBQURM2aNZk7dy5eXl56ZkFERJ4bqqzLE+Pt7c3Vq1c5efIkgYGBVFRUUFFRgYODA9999x379u1j6tSpdO3a1XKO1lC3Tvcvo2cymSgqKsLGxoZt27bxxhtvcOPGDd5//33s7Ozo168fffv2/cFzRURErJlSkDwxHh4e9OnTh/j4eK5evYrBYLCELkdHxwfWTq+oqFBQt0L3wnZxcTEffvghiYmJZGdns3LlSsrLy8nNzSU4OBhnZ2f8/PzIysqqdL6CuoiIPE+UhOSJsbe3Z9CgQTg5OTFjxgzOnTvHN998w6xZs8jIyCA4OLjSeLW+WJeioiLgbtjOzMxk+PDhuLq6kpWVxZAhQ7h16xYpKSkcOXKE06dP88EHHxAdHc3o0aOf8sxFRESeHm2KJE9cTk4Oq1ev5vz589SsWZM6deowZ84cQG0v1urixYusWbOGsWPH4u3tzfbt23F2dqZ9+/aMHz+eHj16EBYWhpubGwsXLiQ7O5uoqCg6d+4M6PdCRESeXwrr8tQUFxdTXFxMjRo1APUiW7Mvv/ySbdu2YWNjw8SJE/nXv/7Frl27sLGxYejQoURERDBp0iTCw8MJCQmx7FyqkC4iIs873QXlqXFycqJ69erA3cqpgrr1KSsrA8DPz4/q1avz5ZdfsmXLFsLDwwHo2LEjERERFBYWcu3aNerUqQPcfYZBzyyIiIhoNRh5yu71pSuUWSdbW1vMZjNjxozB3d2d2rVrc+TIEcxmM5MnT2by5Mnk5+eTmppK586d8ff3t5yrZxZEREQU1kXkN3BvE6uysjLS09NxdHTkgw8+oKSkhFOnTpGYmEirVq3YuHEjly9fplu3boSEhADqTxcREfk+3RFF5LEzGAycOHGCxYsXYzQa+eKLL8jMzMTR0ZEWLVpQWlrKokWLyMvLo0uXLgrqIiIiP0J3RRF57A4ePMjatWvx8/OjQ4cO9OvXj40bN1JaWkqtWrVwc3OjdevWeHp6VjpPQV1ERKQytcGIyK92/0o+R48e5ZtvvqFu3boAhIaGEh8fz2uvvUbdunUxGAzExsZib29vaZkRERGRB2npRhH5Vb4f1FNSUmjYsCGNGzdmxowZODg4MGbMGGrVqmU5bjKZ6N69O6C2FxERkYdRWBeRX+369etMmTIFFxcXbt68SaNGjYiJiWHatGm0b9+eQYMGWQL7PVpXX0RE5OFU0hKRX+z+9/jLly8nMDCQZcuW8fHHH5Oenk58fDyzZ89m586dHD58mPLy8krnKKiLiIg8nMK6iPwiCQkJrFixgn379gFQWlpKdnY2rVu3BsDOzo7FixezdetWatasSUxMDIGBgWp3EREReQS6e4rIzzZ//nwSEhJwd3dnypQpXLx4EQcHBwICAoiLi6O0tBQAd3d3mjdvjtlspmvXrnh6ej5QWRcREZGH02owIvJQJpOJUaNG4eXlRXx8PAaDgbS0NA4cOMCdO3fo1q0bBQUFREVFMWHCBOLi4mjSpAlubm6Wa6iyLiIi8ssprIvIQ3399ddcu3aNwYMHYzAY2LJlC0lJSXTv3p3Dhw/ToEED3n33XWxsbPj3v/9NcHAwf/rTnwC0NKOIiMivoNVgROShysvLOXDgABs3bsTNzQ2j0ci0adNo2rQpR48eZfXq1UybNo1mzZo9cJ4q6iIiIo9Od1EReSgbGxuCg4MJDQ3l1KlTjBs3jqZNmwLw+9//HrPZTHFxcaVzKioqFNRFRER+Jd1JReRncXBwYMCAAQwdOpRVq1ZhNpsBmDVrFi4uLvj4+FQar9YXERGRX09tMCLyi9y4cYO4uDi+++47SktLqVevHrNmzQLU9iIiIvK46a4qIr9InTp1eOONN7hx4wa+vr6WoF5WVqagLiIi8pipsi4ijyQ/P58aNWoAqqiLiIj8VhTWReRXUVAXERH57Sisi4iIiIhUUSqHiYiIiIhUUQrrIiIiIiJVlMK6iIiIiEgVpbAuImJlRo4cia+vL/v27fvJcWVlZXTu3Jk2bdpgNBofy2svWrQIX19fDh48+MjXSExMJCsr67HMR0TkWaewLiJiZfr37w/A7t27f3Lc0aNHyc3NpXfv3ri4uDyW1+7YsSPR0dE0btz4kc6fN28e77zzDoWFhY9lPiIizzq7pz0BERF5vHr27ImrqysHDhygqKgIZ2fnHxy3Y8cOAAYMGPDYXrtTp0506tTpkc+/cePGY5uLiIg1UGVdRMTKODk5ERYWhtFoJDk5+QfHFBUVsW/fPry8vAgMDHyyExQRkZ9NYV1ExArdq5Z//vnnP3j8wIEDGI1G+vfvj8FgAODOnTssW7aMiIgI2rRpQ6tWrejVqxcLFy6kqKjIcu6xY8fw9fXl008/ZcKECbRq1YqgoCDOnj37oz3r58+fZ/To0QQGBuLv78+AAQPYvHlzpTHBwcGWan+/fv3o2bMnx48fx9fXl6lTpz7wPVRUVBASEkJISAjaMkRErJXCuoiIFWrXrh0NGzbk0KFD3Llz54HjO3bswGAwWEK9yWRi+PDhLFu2jHr16vH6668zcOBAjEYjq1at4u9///sD11i6dCnp6ekMHTqUFi1a0Lx58x+cy8GDBxkyZAinTp2iR48eDB06FJPJxLvvvsvMmTMt4958802aNWsGwJAhQxg2bBgdOnTA09OTvXv3UlJSUum6p0+fJisri4iICMsbDhERa6OedRERK2QwGIiMjGT58uUcOHCAiIgIy7G8vDxSUlJo164d3t7ewN0KfGpqKtHR0YwbN84y9m9/+xs9e/YkKSmJ0tJSHBwcLMeMRiOJiYnUrl37R+dhNBqZOnUq1atXJyEhAU9PTwBiYmL461//yqZNmwgNDSUoKIg333yTtLQ0Ll68yOuvv24J7hEREcTFxZGcnEzv3r0t175Xhf/+9yYiYm1UWRcRsVL3VoW5vxVm9+7dmEymSg+WtmzZkrlz5xIVFVVprLu7Oy1atMBsNnPr1q1Kx9q3b/+TQR1g79695Ofn8+c//9kS1AFsbW2ZNGkSANu2bftZ38fOnTstXystLWXPnj34+/vTpEmTnzxfRORZpsq6iIiVeuGFFwgICCAlJYWCggKqVasG3A29zs7OlarUPj4++Pj4UFJSwtmzZ7ly5QoZGRmkpaVx+vRpAMrLyytd38vL66FzSEtLA+72rC9duvSB4zY2NqSnp//kNV588UVat25NcnIyt2/fxt3dncOHD3Pr1i0iIyMfOgcRkWeZwrqIiBUbMGAAZ86cISkpiUGDBpGVlcWZM2eIiIjAzc3NMq68vJyVK1eybt06CgoKAKhduzYBAQF4enryv//974GHOJ2cnB76+rdv3wYqV8Xvd3/F/odERkZy7tw59u7dy8CBA0lMTMTe3p4+ffo89FwRkWeZ2mBERKzYK6+8gqOjo2WDpF27dlFRUfHA2uqrVq1iyZIlvPTSS3z00UccPXqUY8eOsWzZMho0aPDIr39vs6UNGzbw1Vdf/eCfY8eOPfQ6ffv2xd7ent27d1NUVERycjJdunShVq1ajzw3EZFngcK6iIgVc3d3p0ePHhw/fpyCggL27NmDp6cnHTt2rDRu586d2Nvbs3z5coKCgqhTpw5wd3nEy5cvW/7+S/n6+gKQmpr6wLGbN2/y3nvvkZiYaPnaj63qUqNGDbp3787x48fZv38/JSUlaoERkeeCwrqIiJXr378/ZrOZTz/9lLS0NCIjIx8IxQ4ODpjNZvLy8ip9fenSpWRnZwNgNpt/8Wv36tULFxcX/vnPf5KRkVHp2Pz58/n444+5du2a5Wt2dne7M00m0wPXioyMpLS0lA8//JBq1aoREhLyi+cjIvKsUc+6iIiVCwoKwsPDgxUrVgA80AIDd5c/TE1N5bXXXiMsLAw7OztOnDjBhQsXqF27Nrm5ueTl5VmWevy5atSowZw5c5g8eTL9+/enR48eeHh4cPLkSVJTU2ndujUjRoywjK9Xrx4A//jHP+jcuTNjxoyxHOvatSu1atUiKyuLwYMHV1pGUkTEWqmyLiJi5WxtbenXrx9FRUW0bduWRo0aPTAmKiqK6dOnU61aNRISEti1axdubm4sWrSI2NhYAA4fPvxIrx8eHs4nn3xChw4dOHz4MBs3bqSoqIjo6GjWrFlj6WsHGDZsGJ06deLcuXOsX7+e4uJiyzF7e3tCQ0MB1AIjIs8NQ4X2aBYRkWfEoEGDyMvLY9++fdq1VESeC6qsi4jIM+HQoUOcP3+eV199VUFdRJ4bqqyLiEiVNmfOHE6ePMmlS5eoWbMmu3fvtmzwJCJi7VRZFxGRKs3Dw4Nr167h4+PDihUrFNRF5LmiyrqIiIiISBWlyrqIiIiISBWlsC4iIiIiUkUprIuIiIiIVFEK6yIiIiIiVZTCuoiIiIhIFfV/cRanOKRnN5AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Label distribution visualization.\n",
    "sns.set(rc = {'figure.figsize':(12, 8)})\n",
    "chart = sns.countplot(topN_data.variety, palette = \"mako\", order = topN_data['variety'].value_counts().index)\n",
    "plt.title(\"Number of Labels Per Variety \", fontsize = 30)\n",
    "chart.set_xlabel(\"Variety\", fontsize = 20)\n",
    "chart.set_ylabel(\"Count\", fontsize = 20)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation = 40, horizontalalignment = 'right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews:  60612\n",
      "Number of labels:  10\n",
      "Label distribution: \n",
      " Pinot Noir                  11280\n",
      "Chardonnay                   9977\n",
      "Cabernet Sauvignon           8199\n",
      "Red Blend                    7525\n",
      "Bordeaux-style Red Blend     6023\n",
      "Riesling                     4356\n",
      "Sauvignon Blanc              4178\n",
      "Syrah                        3511\n",
      "Rosé                         2875\n",
      "Merlot                       2688\n",
      "Name: variety, dtype: int64\n",
      "Average word length of reviews:  47.71956048307266\n"
     ]
    }
   ],
   "source": [
    "text_ls, label_ls = summary_statistics(topN_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = review_processing(label_ls, text_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 rows of processed dataset: \n",
      "                                                 text            label\n",
      "0  [pineapple, rind, lemon, pith, orange, blossom...         Riesling\n",
      "1  [much, like, regular, bottling, comes, across,...       Pinot Noir\n",
      "2  [zesty, orange, peels, apple, notes, abound, s...         Riesling\n",
      "3  [ripe, aromas, dark, berries, mingle, ample, n...        Red Blend\n",
      "4  [a, sleek, mix, tart, berry, stem, herb, along...       Pinot Noir\n",
      "5  [oak, earth, intermingle, around, robust, arom...       Pinot Noir\n",
      "6  [aromas, suggest, mature, berry, scorched, ear...        Red Blend\n",
      "7  [merlot, nero, form, base, easy, red, wine, wo...        Red Blend\n",
      "8  [rustic, dry, flavors, berries, currants, lico...        Red Blend\n",
      "9  [this, shows, tart, green, gooseberry, flavor,...  Sauvignon Blanc\n"
     ]
    }
   ],
   "source": [
    "print(\"The first 10 rows of processed dataset: \\n\", processed_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataframe successfully saved into CSV as 'cleaned_reviews.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_data.to_csv('cleaned_reviews.csv')\n",
    "print(\"Cleaned dataframe successfully saved into CSV as 'cleaned_reviews.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in from CSV so that tokenized word lists are converted to str format, preparing for fit_transform in vectorization.\n",
    "df = pd.read_csv(\"cleaned_reviews.csv\")\n",
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and train sets\n",
    "X_train, X_test, y_train, y_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TfidfVectorizer to transform text into feature vectors that can be used as input to estimator. \n",
    "# Set max_df = 0.90 so as to ignore terms that appear in more than 90% of the documents.\n",
    "# Set min_df = 50 so as to ignore terms that appear in less than 50 documents.\n",
    "# 1gram transformed data\n",
    "train_x_1gram, test_x_1gram = tfidf_transform(X_train, X_test, min_df = 50, max_df = 0.90, ngram = (1,1))\n",
    "# 1gram+2gram transformed data\n",
    "train_x_1gram2gram, test_x_1gram2gram = tfidf_transform(X_train, X_test, min_df = 50, max_df = 0.90, ngram = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram with C = 1 (default): \n",
      "Precision: 0.7942627513675696\n",
      "Recall:  0.7188607772010857\n",
      "F1 score:  0.7428031464836504\n",
      "Accuracy:  0.7700175978882534\n",
      "Micro-averaged F1-score:  0.7428031464836504\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "\n",
    "# 1gram, C = 1\n",
    "print(\"Results for 1gram with C = 1 (default): \")\n",
    "# For parameter multi_class, if the option chosen is ‘ovr’, then a binary problem is fit for each label.\n",
    "# For parameter C, it stands for inverse of regularization strength; smaller values specify stronger regularization.\n",
    "lr1 = LogisticRegression(C = 1, penalty = 'l2', max_iter = 100, random_state = 42, multi_class = 'ovr')\n",
    "model1 = lr1.fit(train_x_1gram, y_train)\n",
    "pred1 = model1.predict(test_x_1gram)\n",
    "score_metrics(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram with C = 0.5: \n",
      "Precision: 0.8000658603920044\n",
      "Recall:  0.7079526055001143\n",
      "F1 score:  0.7351014578688708\n",
      "Accuracy:  0.7649032116146063\n",
      "Micro-averaged F1-score:  0.7351014578688708\n"
     ]
    }
   ],
   "source": [
    "# 1gram, C = 0.5\n",
    "print(\"Results for 1gram with C = 0.5: \")\n",
    "lr2 = LogisticRegression(C = 0.5, penalty = 'l2', max_iter = 100, random_state = 42, multi_class = 'ovr')\n",
    "model2 = lr2.fit(train_x_1gram, y_train)\n",
    "pred2 = model2.predict(test_x_1gram)\n",
    "score_metrics(y_test, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram+2gram with C = 1 (default): \n",
      "Precision: 0.8016626612779161\n",
      "Recall:  0.7205226292472924\n",
      "F1 score:  0.745735244442101\n",
      "Accuracy:  0.773152221733392\n",
      "Micro-averaged F1-score:  0.745735244442101\n"
     ]
    }
   ],
   "source": [
    "# 1gram+2gram, C = 1\n",
    "print(\"Results for 1gram+2gram with C = 1 (default): \")\n",
    "lr3 = LogisticRegression(C = 1, penalty = 'l2', max_iter = 100, random_state = 42, multi_class = 'ovr')\n",
    "model3 = lr3.fit(train_x_1gram2gram, y_train)\n",
    "pred3 = model3.predict(test_x_1gram2gram)\n",
    "score_metrics(y_test, pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram+2gram with C = 0.5: \n",
      "Precision: 0.8050652992881837\n",
      "Recall:  0.7055834245164656\n",
      "F1 score:  0.7339278828615952\n",
      "Accuracy:  0.7652331720193577\n",
      "Micro-averaged F1-score:  0.7339278828615952\n"
     ]
    }
   ],
   "source": [
    "# 1gram+2gram, C = 0.5\n",
    "print(\"Results for 1gram+2gram with C = 0.5: \")\n",
    "lr4 = LogisticRegression(C = 0.5, penalty = 'l2', max_iter = 100, random_state = 42, multi_class = 'ovr')\n",
    "model4 = lr4.fit(train_x_1gram2gram, y_train)\n",
    "pred4 = model4.predict(test_x_1gram2gram)\n",
    "score_metrics(y_test, pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram with C = 1 (default) and loss = hinge: \n",
      "Precision: 0.770376526671852\n",
      "Recall:  0.7261278340340434\n",
      "F1 score:  0.7414931007943416\n",
      "Accuracy:  0.7680378354597448\n",
      "Micro-averaged F1-score:  0.7414931007943416\n"
     ]
    }
   ],
   "source": [
    "# 2. SVM\n",
    "\n",
    "# 1gram, C = 1, loss = hinge\n",
    "print(\"Results for 1gram with C = 1 (default) and loss = hinge: \")\n",
    "svm1 = LinearSVC(C = 1, loss = 'hinge', random_state = 42)\n",
    "model1 = svm1.fit(train_x_1gram, y_train)\n",
    "pred1 = model1.predict(test_x_1gram)\n",
    "score_metrics(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram with C = 1 (default) and loss = squared_hinge: \n",
      "Precision: 0.765109656015204\n",
      "Recall:  0.7269123619422821\n",
      "F1 score:  0.741172153848428\n",
      "Accuracy:  0.7674329080510339\n",
      "Micro-averaged F1-score:  0.741172153848428\n"
     ]
    }
   ],
   "source": [
    "# 1gram, C = 1, loss = squared_hinge\n",
    "print(\"Results for 1gram with C = 1 (default) and loss = squared_hinge: \")\n",
    "svm2 = LinearSVC(C = 1, loss = 'squared_hinge', random_state = 42)\n",
    "model2 = svm2.fit(train_x_1gram, y_train)\n",
    "pred2 = model2.predict(test_x_1gram)\n",
    "score_metrics(y_test, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram with C = 0.5 and loss = squared_hinge: \n",
      "Precision: 0.7754149296070498\n",
      "Recall:  0.7289762634628475\n",
      "F1 score:  0.7455851641493958\n",
      "Accuracy:  0.7712274527056753\n",
      "Micro-averaged F1-score:  0.7455851641493958\n"
     ]
    }
   ],
   "source": [
    "# 1gram, C = 0.5, loss = squared_hinge\n",
    "print(\"Results for 1gram with C = 0.5 and loss = squared_hinge: \")\n",
    "svm3 = LinearSVC(C = 0.5, loss = 'squared_hinge', random_state = 42)\n",
    "model3 = svm3.fit(train_x_1gram, y_train)\n",
    "pred3 = model3.predict(test_x_1gram)\n",
    "score_metrics(y_test, pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram+2gram with C = 1 (default) and loss = hinge: \n",
      "Precision: 0.7707159254012571\n",
      "Recall:  0.7262114626170162\n",
      "F1 score:  0.7416517825237868\n",
      "Accuracy:  0.7688627364716234\n",
      "Micro-averaged F1-score:  0.7416517825237868\n"
     ]
    }
   ],
   "source": [
    "# 1gram+2gram, C = 1, loss = hinge\n",
    "print(\"Results for 1gram+2gram with C = 1 (default) and loss = hinge: \")\n",
    "svm4 = LinearSVC(C = 1, loss = 'hinge', random_state = 42)\n",
    "model4 = svm4.fit(train_x_1gram2gram, y_train)\n",
    "pred4 = model4.predict(test_x_1gram2gram)\n",
    "score_metrics(y_test, pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram+2gram with C = 1 (default) and loss = squared_hinge: \n",
      "Precision: 0.7601336212686178\n",
      "Recall:  0.7277973309997148\n",
      "F1 score:  0.7403406012327195\n",
      "Accuracy:  0.7661680598328201\n",
      "Micro-averaged F1-score:  0.7403406012327195\n"
     ]
    }
   ],
   "source": [
    "# 1gram+2gram, C = 1, loss = squared_hinge\n",
    "print(\"Results for 1gram+2gram with C = 1 (default) and loss = squared_hinge: \")\n",
    "svm5 = LinearSVC(C = 1, loss = 'squared_hinge', random_state = 42)\n",
    "model5 = svm5.fit(train_x_1gram2gram, y_train)\n",
    "pred5 = model5.predict(test_x_1gram2gram)\n",
    "score_metrics(y_test, pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1gram+2gram with C = 0.5 and loss = squared_hinge: \n",
      "Precision: 0.7738184916642525\n",
      "Recall:  0.7299463175485849\n",
      "F1 score:  0.7457745074462696\n",
      "Accuracy:  0.7715574131104268\n",
      "Micro-averaged F1-score:  0.7457745074462696\n"
     ]
    }
   ],
   "source": [
    "# 1gram+2gram, C = 0.5, loss = squared_hinge\n",
    "print(\"Results for 1gram+2gram with C = 0.5 and loss = squared_hinge: \")\n",
    "svm6 = LinearSVC(C = 0.5, loss = 'squared_hinge', random_state = 42)\n",
    "model6 = svm6.fit(train_x_1gram2gram, y_train)\n",
    "pred6 = model6.predict(test_x_1gram2gram)\n",
    "score_metrics(y_test, pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fasttext\n",
    "\n",
    "# Fasttext data preparation. \n",
    "def fasttext_data_prep(labels, texts):\n",
    "\n",
    "    fasttext_df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "    # Add __label__ prefix in front of all labels.\n",
    "    fasttext_df['label'] = '__label__'+  fasttext_df['label'].astype(str)\n",
    "    # Convert to lower cases, remove stopwords, and non-alphabetical chars.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    fasttext_df['text'] = fasttext_df.apply(lambda x: ' '.join(i.lower() for i in x['text'].split() if i.isalpha() and i not in stop_words), axis = 1)\n",
    "    # Combine these two columns into our new labels in format: __label__ text.\n",
    "    fasttext_df['new_label'] = fasttext_df.apply(lambda x: str(x['label']) + ' ' + str(x['text']), axis = 1)\n",
    "    print(\"The first 10 rows of fasttext dataset: \\n\", fasttext_df.head(10))\n",
    "    \n",
    "    return fasttext_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fasttext performance evaluation metrics.\n",
    "def fasttext_metrics(evaluation):\n",
    "    precision = evaluation[1]\n",
    "    recall = evaluation[2]\n",
    "    f1 = 2*precision*recall / (precision+recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 rows of fasttext dataset: \n",
      "                                                 text  \\\n",
      "0  pineapple lemon pith orange blossom start the ...   \n",
      "1  much like regular bottling comes across rather...   \n",
      "2  zesty orange peels apple notes abound off dry ...   \n",
      "3  ripe aromas dark berries mingle ample notes bl...   \n",
      "4  a sleek mix tart stem along hint oak fair valu...   \n",
      "5  oak earth intermingle around robust aromas wet...   \n",
      "6  aromas suggest mature scorched toast the palat...   \n",
      "7  merlot nero form base easy red wine would pair...   \n",
      "8  rustic flavors licorice made cabernet franc ca...   \n",
      "9  this shows green gooseberry flavor similar new...   \n",
      "\n",
      "                      label                                          new_label  \n",
      "0         __label__Riesling  __label__Riesling pineapple lemon pith orange ...  \n",
      "1       __label__Pinot Noir  __label__Pinot Noir much like regular bottling...  \n",
      "2         __label__Riesling  __label__Riesling zesty orange peels apple not...  \n",
      "3        __label__Red Blend  __label__Red Blend ripe aromas dark berries mi...  \n",
      "4       __label__Pinot Noir  __label__Pinot Noir a sleek mix tart stem alon...  \n",
      "5       __label__Pinot Noir  __label__Pinot Noir oak earth intermingle arou...  \n",
      "6        __label__Red Blend  __label__Red Blend aromas suggest mature scorc...  \n",
      "7        __label__Red Blend  __label__Red Blend merlot nero form base easy ...  \n",
      "8        __label__Red Blend  __label__Red Blend rustic flavors licorice mad...  \n",
      "9  __label__Sauvignon Blanc  __label__Sauvignon Blanc this shows green goos...  \n"
     ]
    }
   ],
   "source": [
    "# Data preparation.\n",
    "fasttext_df = fasttext_data_prep(label_ls, text_ls)\n",
    "# Split into testing and training sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(fasttext_df['new_label'], fasttext_df['label'], test_size = 0.3, random_state = 42)\n",
    "# Saving testing and training data into txt file for uniform formatting.\n",
    "X_train.to_csv('fasttext_X_train.txt',index = False, header = False)\n",
    "X_test.to_csv('fasttext_X_test.txt',index = False, header = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9274637043554773\n",
      "Recall:  0.9274637043554773\n",
      "F1 score:  0.9274637043554773\n"
     ]
    }
   ],
   "source": [
    "# lr = 1.0, wordNgrams = 1\n",
    "fasttext1 = fasttext.train_supervised('fasttext_X_train.txt', lr = 1.0, wordNgrams = 1, epoch = 25)                                       \n",
    "evaluation1 = fasttext1.test('fasttext_X_test.txt')\n",
    "fasttext_metrics(evaluation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9385173779146503\n",
      "Recall:  0.9385173779146503\n",
      "F1 score:  0.9385173779146503\n"
     ]
    }
   ],
   "source": [
    "# lr = 1.0, wordNgrams = 2\n",
    "fasttext2 = fasttext.train_supervised('fasttext_X_train.txt', lr = 1.0, wordNgrams = 2, epoch = 25)                                       \n",
    "evaluation2 = fasttext2.test('fasttext_X_test.txt')\n",
    "fasttext_metrics(evaluation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9392872855257369\n",
      "Recall:  0.9392872855257369\n",
      "F1 score:  0.9392872855257369\n"
     ]
    }
   ],
   "source": [
    "# lr = 0.5, wordNgrams = 2\n",
    "fasttext3 = fasttext.train_supervised('fasttext_X_train.txt', lr = 0.5, wordNgrams = 2, epoch = 25)                                       \n",
    "evaluation3 = fasttext3.test('fasttext_X_test.txt')\n",
    "fasttext_metrics(evaluation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9397822261328641\n",
      "Recall:  0.9397822261328641\n",
      "F1 score:  0.9397822261328641\n"
     ]
    }
   ],
   "source": [
    "# lr = 0.05, wordNgrams = 2\n",
    "fasttext4 = fasttext.train_supervised('fasttext_X_train.txt', lr = 0.05, wordNgrams = 2, epoch = 25)                                       \n",
    "evaluation4 = fasttext4.test('fasttext_X_test.txt')\n",
    "fasttext_metrics(evaluation4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CNN\n",
    "# Referencing code from lecture5.py\n",
    "\n",
    "def token_to_index(token, dictionary):\n",
    "    \"\"\"\n",
    "    Given a token and a gensim dictionary, return the token index\n",
    "    if in the dictionary, None otherwise.\n",
    "    Reserve index 0 for padding.\n",
    "    \"\"\"\n",
    "    if token not in dictionary.token2id:\n",
    "        return None\n",
    "    return dictionary.token2id[token] + 1\n",
    "\n",
    "\n",
    "def texts_to_indices(text, dictionary):\n",
    "    \"\"\"\n",
    "    Given a list of tokens (text) and a gensim dictionary, return a list\n",
    "    of token ids.\n",
    "    \"\"\"\n",
    "    result = list(map(lambda x: token_to_index(x, dictionary), text))\n",
    "    return list(filter(None, result))\n",
    "\n",
    "\n",
    "def train(train_texts, train_labels, dictionary, model_file = None, EMBEDDINGS_MODEL_FILE = None):\n",
    "    \"\"\"\n",
    "    Train a word-level CNN text classifier.\n",
    "    :param train_texts: tokenized and normalized texts, a list of token lists, [['sentence', 'blah', 'blah'], ['sentence', '2'], .....]\n",
    "    :param train_labels: the label for each train text\n",
    "    :param dictionary: A gensim dictionary object for the training text tokens\n",
    "    :param model_file: An optional output location for the ML model file\n",
    "    :param EMBEDDINGS_MODEL_FILE: An optinal location for pre-trained word embeddings file location\n",
    "    :return: the produced keras model, the validation accuracy, and the size of the training examples\n",
    "    \"\"\"\n",
    "    assert len(train_texts)==len(train_labels)\n",
    "    # compute the max sequence length\n",
    "    lengths = list(map(lambda x: len(x), train_texts))\n",
    "    a = np.array(lengths)\n",
    "    MAX_SEQUENCE_LENGTH = int(np.percentile(a, SEQUENCE_LENGTH_PERCENTILE))\n",
    "    # convert all texts to dictionary indices\n",
    "    # train_texts_indices = list(map(lambda x: texts_to_indices(x[0], dictionary), train_texts))\n",
    "    train_texts_indices = list(map(lambda x: texts_to_indices(x, dictionary), train_texts))\n",
    "    # pad or truncate the texts\n",
    "    x_data = pad_sequences(train_texts_indices, maxlen = int(MAX_SEQUENCE_LENGTH))\n",
    "    # convert the train labels to one-hot encoded vectors\n",
    "    train_labels = keras.utils.to_categorical(train_labels)\n",
    "    \n",
    "    y_data = train_labels\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # create embeddings matrix from word2vec pre-trained embeddings, if provided\n",
    "    if pretrained_embedding:\n",
    "        embeddings_index = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDINGS_MODEL_FILE, binary=True)\n",
    "        embedding_matrix = np.zeros((len(dictionary) + 1, EMBEDDING_DIM))\n",
    "        for word, i in dictionary.token2id.items():\n",
    "            embedding_vector = embeddings_index[word] if word in embeddings_index else None\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        model.add(Embedding(len(dictionary) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            trainable = TRAINABLE_EMBEDDINGS))\n",
    "    else:\n",
    "        model.add(Embedding(len(dictionary) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length = MAX_SEQUENCE_LENGTH))\n",
    "        \n",
    "    # add drop out for the input layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # add a 1 dimensional conv layer\n",
    "    # a rectified linear activation unit, returns input if input > 0 else 0\n",
    "    model.add(Conv1D(filters = n_filters,\n",
    "                     kernel_size = window_size,\n",
    "                     activation = 'relu'))\n",
    "    \n",
    "    # add a max pooling layer\n",
    "    model.add(MaxPooling1D(MAX_SEQUENCE_LENGTH - window_size + 1))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # add 0 or more fully connected layers with drop out\n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(hidden_units,\n",
    "                        activation=dense_activation,\n",
    "                        kernel_regularizer=l2(l2_penalty),\n",
    "                        bias_regularizer=l2(l2_penalty),\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        bias_initializer='zeros'))\n",
    "\n",
    "    # add the last fully connected layer with softmax activation\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(train_labels[0]),\n",
    "                    activation='softmax',\n",
    "                    kernel_regularizer=l2(l2_penalty),\n",
    "                    bias_regularizer=l2(l2_penalty),\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    bias_initializer='zeros'))\n",
    "\n",
    "    # compile the model, provide an optimizer\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['acc', cnn_f1, cnn_precision, cnn_recall])\n",
    "\n",
    "    # print a summary\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    # train the model with early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    Y = np.array(y_data)\n",
    "\n",
    "    fit = model.fit(x_data,\n",
    "                    Y,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "    print(fit.history.keys())\n",
    "    val_accuracy = fit.history['val_acc'][-1]\n",
    "    val_f1 = fit.history['val_cnn_f1'][-1]\n",
    "    print(\"Accuracy: \", val_accuracy)\n",
    "    print(\"F1-score: \", val_f1)\n",
    "    # save the model\n",
    "\n",
    "    if model_file:\n",
    "        model.save(model_file)\n",
    "    return model, val_accuracy, val_f1\n",
    "\n",
    "# Calculate recall value\n",
    "def cnn_recall(true, pred):\n",
    "    TP = backend.sum(backend.round(backend.clip(true * pred, 0, 1)))\n",
    "    PP = backend.sum(backend.round(backend.clip(true, 0, 1)))\n",
    "    recall = TP / (PP + backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "    \n",
    "# Calculate precision value\n",
    "def cnn_precision(true, pred):\n",
    "    TP = backend.sum(backend.round(backend.clip(true * pred, 0, 1)))\n",
    "    PP = backend.sum(backend.round(backend.clip(pred, 0, 1)))\n",
    "    precision = TP/ (PP + backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "    \n",
    "# Calculate F1-score value\n",
    "def cnn_f1(true, pred):\n",
    "    precision = cnn_precision(true, pred)\n",
    "    recall = cnn_recall(true, pred)\n",
    "    f1 = 2*precision*recall/(precision+recall+backend.epsilon())\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for CNN\n",
    "def cnn_processing(labels, texts):\n",
    "    \n",
    "    # Remove list of stopwords that do not add much meaning to a sentence.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Apply nltk word tokenization, convert to lower cases, remove non-alphabetic chars and stopwords.\n",
    "    texts_tokenized = [tokenization(i, stop_words) for i in texts]\n",
    "    \n",
    "    # Encode labels into numbers.\n",
    "    possible_labels = set(label_ls)\n",
    "    label_dict = {}\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "        \n",
    "    return texts_tokenized, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN data preparation. \n",
    "cnn_texts, label_dict = cnn_processing(label_ls, text_ls)\n",
    "cnn_texts = tuple(cnn_texts)\n",
    "cnn_labels = [label_dict.get(item, item) for item in label_ls]\n",
    "cnn_labels = tuple(cnn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = gensim.corpora.Dictionary(cnn_texts)\n",
    "mydict.save('cnn.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn1: dense_activation = \"relu\", batch_size = 128\n",
    "\n",
    "# model hyper parameters\n",
    "EMBEDDING_DIM = 100\n",
    "SEQUENCE_LENGTH_PERCENTILE = 90\n",
    "n_layers = 2\n",
    "hidden_units = 500\n",
    "batch_size = 128\n",
    "pretrained_embedding = False\n",
    "TRAINABLE_EMBEDDINGS = True\n",
    "patience = 2\n",
    "dropout_rate = 0.3\n",
    "n_filters = 100\n",
    "window_size = 8\n",
    "dense_activation = \"relu\"\n",
    "l2_penalty = 0.0003\n",
    "epochs = 10\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 35, 100)           2216600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 35, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 28, 100)           80100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 2,602,710\n",
      "Trainable params: 2,602,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "427/427 [==============================] - 19s 43ms/step - loss: 1.3928 - acc: 0.5247 - cnn_f1: 0.4400 - cnn_precision: 0.6769 - cnn_recall: 0.3413 - val_loss: 0.9255 - val_acc: 0.7171 - val_cnn_f1: 0.6943 - val_cnn_precision: 0.8560 - val_cnn_recall: 0.5850\n",
      "Epoch 2/10\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.8798 - acc: 0.7236 - cnn_f1: 0.7139 - cnn_precision: 0.8308 - cnn_recall: 0.6266 - val_loss: 0.8092 - val_acc: 0.7494 - val_cnn_f1: 0.7479 - val_cnn_precision: 0.8233 - val_cnn_recall: 0.6856\n",
      "Epoch 3/10\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.7610 - acc: 0.7657 - cnn_f1: 0.7616 - cnn_precision: 0.8499 - cnn_recall: 0.6907 - val_loss: 0.7495 - val_acc: 0.7656 - val_cnn_f1: 0.7653 - val_cnn_precision: 0.8493 - val_cnn_recall: 0.6970\n",
      "Epoch 4/10\n",
      "427/427 [==============================] - 17s 40ms/step - loss: 0.6970 - acc: 0.7888 - cnn_f1: 0.7851 - cnn_precision: 0.8596 - cnn_recall: 0.7231 - val_loss: 0.7528 - val_acc: 0.7658 - val_cnn_f1: 0.7679 - val_cnn_precision: 0.8358 - val_cnn_recall: 0.7107\n",
      "Epoch 5/10\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.6506 - acc: 0.8024 - cnn_f1: 0.8013 - cnn_precision: 0.8701 - cnn_recall: 0.7431 - val_loss: 0.7311 - val_acc: 0.7733 - val_cnn_f1: 0.7761 - val_cnn_precision: 0.8494 - val_cnn_recall: 0.7150\n",
      "Epoch 6/10\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.6101 - acc: 0.8167 - cnn_f1: 0.8161 - cnn_precision: 0.8772 - cnn_recall: 0.7635 - val_loss: 0.7324 - val_acc: 0.7753 - val_cnn_f1: 0.7788 - val_cnn_precision: 0.8462 - val_cnn_recall: 0.7220\n",
      "Epoch 7/10\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.5849 - acc: 0.8242 - cnn_f1: 0.8235 - cnn_precision: 0.8807 - cnn_recall: 0.7738 - val_loss: 0.7327 - val_acc: 0.7687 - val_cnn_f1: 0.7692 - val_cnn_precision: 0.8369 - val_cnn_recall: 0.7121\n",
      "dict_keys(['loss', 'acc', 'cnn_f1', 'cnn_precision', 'cnn_recall', 'val_loss', 'val_acc', 'val_cnn_f1', 'val_cnn_precision', 'val_cnn_recall'])\n",
      "Accuracy:  0.76872318983078\n",
      "F1-score:  0.7691637873649597\n",
      "WARNING:tensorflow:From /Users/vesper7367/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/vesper7367/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: cnn1.model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f95a7901240>,\n",
       " 0.76872318983078,\n",
       " 0.7691637873649597)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = gensim.corpora.Dictionary.load('cnn.dict')\n",
    "train(cnn_texts, cnn_labels, mydict, model_file = 'cnn1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn2: dense_activation = \"sigmoid\", batch_size = 128\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "SEQUENCE_LENGTH_PERCENTILE = 90\n",
    "n_layers = 2\n",
    "hidden_units = 500\n",
    "batch_size = 128\n",
    "pretrained_embedding = False\n",
    "TRAINABLE_EMBEDDINGS = True\n",
    "patience = 2\n",
    "dropout_rate = 0.3\n",
    "n_filters = 100\n",
    "window_size = 8\n",
    "dense_activation = \"sigmoid\"\n",
    "l2_penalty = 0.0003\n",
    "epochs = 10\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 100)           2216600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 35, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 28, 100)           80100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 2,602,710\n",
      "Trainable params: 2,602,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "427/427 [==============================] - 19s 44ms/step - loss: 1.8078 - acc: 0.3690 - cnn_f1: 0.2013 - cnn_precision: 0.4990 - cnn_recall: 0.1311 - val_loss: 1.4435 - val_acc: 0.4802 - val_cnn_f1: 0.4053 - val_cnn_precision: 0.7250 - val_cnn_recall: 0.2824\n",
      "Epoch 2/10\n",
      "427/427 [==============================] - 17s 39ms/step - loss: 1.2977 - acc: 0.5547 - cnn_f1: 0.4823 - cnn_precision: 0.7331 - cnn_recall: 0.3625 - val_loss: 1.2783 - val_acc: 0.5525 - val_cnn_f1: 0.5393 - val_cnn_precision: 0.6685 - val_cnn_recall: 0.4527\n",
      "Epoch 3/10\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 1.1169 - acc: 0.6389 - cnn_f1: 0.6036 - cnn_precision: 0.7653 - cnn_recall: 0.4997 - val_loss: 1.0863 - val_acc: 0.6382 - val_cnn_f1: 0.6309 - val_cnn_precision: 0.7339 - val_cnn_recall: 0.5541\n",
      "Epoch 4/10\n",
      "427/427 [==============================] - 17s 39ms/step - loss: 0.9970 - acc: 0.6879 - cnn_f1: 0.6711 - cnn_precision: 0.7916 - cnn_recall: 0.5837 - val_loss: 1.0280 - val_acc: 0.6818 - val_cnn_f1: 0.6733 - val_cnn_precision: 0.7517 - val_cnn_recall: 0.6104\n",
      "Epoch 5/10\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.9101 - acc: 0.7218 - cnn_f1: 0.7126 - cnn_precision: 0.8138 - cnn_recall: 0.6346 - val_loss: 0.9361 - val_acc: 0.7239 - val_cnn_f1: 0.7104 - val_cnn_precision: 0.8220 - val_cnn_recall: 0.6263\n",
      "Epoch 6/10\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.8519 - acc: 0.7425 - cnn_f1: 0.7380 - cnn_precision: 0.8272 - cnn_recall: 0.6670 - val_loss: 0.9141 - val_acc: 0.7204 - val_cnn_f1: 0.7213 - val_cnn_precision: 0.8004 - val_cnn_recall: 0.6571\n",
      "Epoch 7/10\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.8031 - acc: 0.7604 - cnn_f1: 0.7571 - cnn_precision: 0.8373 - cnn_recall: 0.6915 - val_loss: 0.8834 - val_acc: 0.7356 - val_cnn_f1: 0.7333 - val_cnn_precision: 0.8064 - val_cnn_recall: 0.6730\n",
      "Epoch 8/10\n",
      "427/427 [==============================] - 17s 39ms/step - loss: 0.7720 - acc: 0.7733 - cnn_f1: 0.7693 - cnn_precision: 0.8444 - cnn_recall: 0.7070 - val_loss: 0.8653 - val_acc: 0.7395 - val_cnn_f1: 0.7432 - val_cnn_precision: 0.8032 - val_cnn_recall: 0.6922\n",
      "Epoch 9/10\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.7444 - acc: 0.7802 - cnn_f1: 0.7780 - cnn_precision: 0.8488 - cnn_recall: 0.7187 - val_loss: 0.8383 - val_acc: 0.7481 - val_cnn_f1: 0.7488 - val_cnn_precision: 0.8099 - val_cnn_recall: 0.6967\n",
      "Epoch 10/10\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.7159 - acc: 0.7907 - cnn_f1: 0.7899 - cnn_precision: 0.8553 - cnn_recall: 0.7343 - val_loss: 0.8741 - val_acc: 0.7303 - val_cnn_f1: 0.7333 - val_cnn_precision: 0.8013 - val_cnn_recall: 0.6763\n",
      "dict_keys(['loss', 'acc', 'cnn_f1', 'cnn_precision', 'cnn_recall', 'val_loss', 'val_acc', 'val_cnn_f1', 'val_cnn_precision', 'val_cnn_recall'])\n",
      "Accuracy:  0.7302870154380798\n",
      "F1-score:  0.7333036065101624\n",
      "INFO:tensorflow:Assets written to: cnn2.model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f95aa32b550>,\n",
       " 0.7302870154380798,\n",
       " 0.7333036065101624)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = gensim.corpora.Dictionary.load('cnn.dict')\n",
    "train(cnn_texts, cnn_labels, mydict, model_file = 'cnn2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn3: dense_activation = \"relu\", batch_size = 32\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "SEQUENCE_LENGTH_PERCENTILE = 90\n",
    "n_layers = 2\n",
    "hidden_units = 500\n",
    "batch_size = 32\n",
    "pretrained_embedding = False\n",
    "TRAINABLE_EMBEDDINGS = True\n",
    "patience = 2\n",
    "dropout_rate = 0.3\n",
    "n_filters = 100\n",
    "window_size = 8\n",
    "dense_activation = \"relu\"\n",
    "l2_penalty = 0.0003\n",
    "epochs = 10\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 35, 100)           2216600   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 35, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 28, 100)           80100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 2,602,710\n",
      "Trainable params: 2,602,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1705/1705 [==============================] - 33s 20ms/step - loss: 1.2240 - acc: 0.5875 - cnn_f1: 0.5293 - cnn_precision: 0.7419 - cnn_recall: 0.4313 - val_loss: 0.8847 - val_acc: 0.7189 - val_cnn_f1: 0.7145 - val_cnn_precision: 0.8145 - val_cnn_recall: 0.6397\n",
      "Epoch 2/10\n",
      "1705/1705 [==============================] - 34s 20ms/step - loss: 0.8515 - acc: 0.7420 - cnn_f1: 0.7309 - cnn_precision: 0.8331 - cnn_recall: 0.6538 - val_loss: 0.8033 - val_acc: 0.7560 - val_cnn_f1: 0.7578 - val_cnn_precision: 0.8366 - val_cnn_recall: 0.6953\n",
      "Epoch 3/10\n",
      "1705/1705 [==============================] - 33s 20ms/step - loss: 0.7806 - acc: 0.7666 - cnn_f1: 0.7610 - cnn_precision: 0.8488 - cnn_recall: 0.6921 - val_loss: 0.7679 - val_acc: 0.7695 - val_cnn_f1: 0.7684 - val_cnn_precision: 0.8463 - val_cnn_recall: 0.7065\n",
      "Epoch 4/10\n",
      "1705/1705 [==============================] - 32s 19ms/step - loss: 0.7482 - acc: 0.7787 - cnn_f1: 0.7753 - cnn_precision: 0.8577 - cnn_recall: 0.7097 - val_loss: 0.7486 - val_acc: 0.7783 - val_cnn_f1: 0.7733 - val_cnn_precision: 0.8461 - val_cnn_recall: 0.7146\n",
      "Epoch 5/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.7203 - acc: 0.7902 - cnn_f1: 0.7847 - cnn_precision: 0.8625 - cnn_recall: 0.7219 - val_loss: 0.7396 - val_acc: 0.7809 - val_cnn_f1: 0.7714 - val_cnn_precision: 0.8596 - val_cnn_recall: 0.7026\n",
      "Epoch 6/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.7086 - acc: 0.7966 - cnn_f1: 0.7907 - cnn_precision: 0.8669 - cnn_recall: 0.7289 - val_loss: 0.7596 - val_acc: 0.7639 - val_cnn_f1: 0.7609 - val_cnn_precision: 0.8422 - val_cnn_recall: 0.6969\n",
      "Epoch 7/10\n",
      "1705/1705 [==============================] - 32s 19ms/step - loss: 0.6973 - acc: 0.8004 - cnn_f1: 0.7964 - cnn_precision: 0.8700 - cnn_recall: 0.7364 - val_loss: 0.7428 - val_acc: 0.7798 - val_cnn_f1: 0.7728 - val_cnn_precision: 0.8636 - val_cnn_recall: 0.7025\n",
      "dict_keys(['loss', 'acc', 'cnn_f1', 'cnn_precision', 'cnn_recall', 'val_loss', 'val_acc', 'val_cnn_f1', 'val_cnn_precision', 'val_cnn_recall'])\n",
      "Accuracy:  0.7797756791114807\n",
      "F1-score:  0.7727513313293457\n",
      "INFO:tensorflow:Assets written to: cnn3.model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f95e41a8ac8>,\n",
       " 0.7797756791114807,\n",
       " 0.7727513313293457)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = gensim.corpora.Dictionary.load('cnn.dict')\n",
    "train(cnn_texts, cnn_labels, mydict, model_file = 'cnn3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn4: dense_activation = \"sigmoid\", batch_size = 32\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "SEQUENCE_LENGTH_PERCENTILE = 90\n",
    "n_layers = 2\n",
    "hidden_units = 500\n",
    "batch_size = 32\n",
    "pretrained_embedding = False\n",
    "TRAINABLE_EMBEDDINGS = True\n",
    "patience = 2\n",
    "dropout_rate = 0.3\n",
    "n_filters = 100\n",
    "window_size = 8\n",
    "dense_activation = \"sigmoid\"\n",
    "l2_penalty = 0.0003\n",
    "epochs = 10\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 35, 100)           2216600   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 35, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 28, 100)           80100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 2,602,710\n",
      "Trainable params: 2,602,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 1.5092 - acc: 0.4861 - cnn_f1: 0.3897 - cnn_precision: 0.6321 - cnn_recall: 0.2948 - val_loss: 1.1482 - val_acc: 0.6206 - val_cnn_f1: 0.5908 - val_cnn_precision: 0.7494 - val_cnn_recall: 0.4917\n",
      "Epoch 2/10\n",
      "1705/1705 [==============================] - 30s 18ms/step - loss: 1.0521 - acc: 0.6713 - cnn_f1: 0.6539 - cnn_precision: 0.7812 - cnn_recall: 0.5658 - val_loss: 0.9431 - val_acc: 0.7049 - val_cnn_f1: 0.6979 - val_cnn_precision: 0.8048 - val_cnn_recall: 0.6195\n",
      "Epoch 3/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.9343 - acc: 0.7131 - cnn_f1: 0.7075 - cnn_precision: 0.8110 - cnn_recall: 0.6303 - val_loss: 0.8760 - val_acc: 0.7318 - val_cnn_f1: 0.7271 - val_cnn_precision: 0.8190 - val_cnn_recall: 0.6565\n",
      "Epoch 4/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.8673 - acc: 0.7387 - cnn_f1: 0.7317 - cnn_precision: 0.8252 - cnn_recall: 0.6597 - val_loss: 0.8479 - val_acc: 0.7493 - val_cnn_f1: 0.7457 - val_cnn_precision: 0.8132 - val_cnn_recall: 0.6911\n",
      "Epoch 5/10\n",
      "1705/1705 [==============================] - 30s 18ms/step - loss: 0.8187 - acc: 0.7598 - cnn_f1: 0.7561 - cnn_precision: 0.8377 - cnn_recall: 0.6911 - val_loss: 0.8300 - val_acc: 0.7531 - val_cnn_f1: 0.7537 - val_cnn_precision: 0.8237 - val_cnn_recall: 0.6972\n",
      "Epoch 6/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.7911 - acc: 0.7700 - cnn_f1: 0.7668 - cnn_precision: 0.8428 - cnn_recall: 0.7056 - val_loss: 0.8257 - val_acc: 0.7567 - val_cnn_f1: 0.7570 - val_cnn_precision: 0.8273 - val_cnn_recall: 0.7001\n",
      "Epoch 7/10\n",
      "1705/1705 [==============================] - 32s 19ms/step - loss: 0.7668 - acc: 0.7806 - cnn_f1: 0.7787 - cnn_precision: 0.8500 - cnn_recall: 0.7204 - val_loss: 0.8192 - val_acc: 0.7610 - val_cnn_f1: 0.7581 - val_cnn_precision: 0.8165 - val_cnn_recall: 0.7097\n",
      "Epoch 8/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.7507 - acc: 0.7869 - cnn_f1: 0.7862 - cnn_precision: 0.8532 - cnn_recall: 0.7307 - val_loss: 0.8098 - val_acc: 0.7684 - val_cnn_f1: 0.7706 - val_cnn_precision: 0.8180 - val_cnn_recall: 0.7302\n",
      "Epoch 9/10\n",
      "1705/1705 [==============================] - 31s 18ms/step - loss: 0.7384 - acc: 0.7922 - cnn_f1: 0.7907 - cnn_precision: 0.8567 - cnn_recall: 0.7358 - val_loss: 0.7838 - val_acc: 0.7745 - val_cnn_f1: 0.7769 - val_cnn_precision: 0.8416 - val_cnn_recall: 0.7240\n",
      "Epoch 10/10\n",
      "1705/1705 [==============================] - 30s 18ms/step - loss: 0.7215 - acc: 0.7979 - cnn_f1: 0.7978 - cnn_precision: 0.8611 - cnn_recall: 0.7450 - val_loss: 0.7857 - val_acc: 0.7724 - val_cnn_f1: 0.7733 - val_cnn_precision: 0.8437 - val_cnn_recall: 0.7167\n",
      "dict_keys(['loss', 'acc', 'cnn_f1', 'cnn_precision', 'cnn_recall', 'val_loss', 'val_acc', 'val_cnn_f1', 'val_cnn_precision', 'val_cnn_recall'])\n",
      "Accuracy:  0.7723523378372192\n",
      "F1-score:  0.7733009457588196\n",
      "INFO:tensorflow:Assets written to: cnn4.model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f95e41d5278>,\n",
       " 0.7723523378372192,\n",
       " 0.7733009457588196)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = gensim.corpora.Dictionary.load('cnn.dict')\n",
    "train(cnn_texts, cnn_labels, mydict, model_file = 'cnn4.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best fasttext model\n",
    "fasttext4.save_model(\"best_fasttext.bin\")\n",
    "# fasttext_model = fasttext.load_model(\"best_fasttext.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
